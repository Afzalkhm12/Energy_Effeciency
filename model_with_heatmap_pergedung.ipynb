{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8abc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Library berhasil diimpor.\n",
      "📁 Folder sumber data diatur ke: 'sumber_data'\n",
      "📁 Folder hasil akan disimpan di: 'hasil_model_aggregate_pergedung'\n",
      "📊 Batas minimum data untuk pelatihan: 500 baris\n",
      "✅ Sel ini siap.\n",
      "Pastikan Anda telah mengunggah data Anda ke dalam folder 'sumber_data'.\n",
      "✅ Fungsi-fungsi pembantu berhasil didefinisikan.\n",
      "Memulai proses pemuatan dan penggabungan data...\n",
      "✅ Data untuk 'opmc_sdp' berhasil digabungkan, total 52674 baris.\n",
      "✅ Data untuk 'opmc_ahu' berhasil digabungkan, total 43893 baris.\n",
      "✅ Data untuk 'opmc_lift' berhasil digabungkan, total 1121 baris.\n",
      "✅ Data untuk 'witel_ahu' berhasil digabungkan, total 96391 baris.\n",
      "✅ Data untuk 'witel_sdp' berhasil digabungkan, total 96598 baris.\n",
      "✅ Data untuk 'witel_lift' berhasil digabungkan, total 17554 baris.\n",
      "✅ Data untuk 'witel_chiller' berhasil digabungkan, total 1121 baris.\n",
      "\n",
      "--- Peringkat Konsumsi Energi Rata-Rata Terbesar ---\n",
      "1. opmc - LIFT: 326.63 kWh\n",
      "2. witel - CHILLER: 326.63 kWh\n",
      "3. witel - Lantai7_SDP: 57.95 kWh\n",
      "4. witel - Lantai7_AHU: 35.70 kWh\n",
      "5. witel - Lantai6_SDP: 35.65 kWh\n",
      "6. witel - Lantai8_AHU: 35.06 kWh\n",
      "7. witel - Lantai6_AHU: 31.47 kWh\n",
      "8. opmc - Lantai5_AHU: 29.07 kWh\n",
      "9. witel - lantai1_sdp: 24.09 kWh\n",
      "10. witel - Lantai1_SDP: 24.09 kWh\n",
      "11. opmc - Lantai6_SDP: 23.63 kWh\n",
      "12. opmc - Lantai3_AHU: 22.52 kWh\n",
      "13. witel - lift: 20.16 kWh\n",
      "14. witel - LIFT: 20.16 kWh\n",
      "15. opmc - Lantai5_SDP: 18.59 kWh\n",
      "16. witel - lantai1_ahu: 17.54 kWh\n",
      "17. witel - Lantai1_AHU: 17.54 kWh\n",
      "18. witel - Lantai3_SDP: 16.32 kWh\n",
      "19. witel - lantai3_sdp: 16.32 kWh\n",
      "20. opmc - Lantai1_SDP: 15.65 kWh\n",
      "21. opmc - Lantai4_AHU: 13.23 kWh\n",
      "22. witel - lantai2_sdp: 13.12 kWh\n",
      "23. witel - Lantai2_SDP: 13.12 kWh\n",
      "24. witel - Lantai5_SDP: 12.35 kWh\n",
      "25. witel - Lantai5_AHU: 12.31 kWh\n",
      "26. opmc - Lantai2_SDP: 7.98 kWh\n",
      "27. opmc - Lantai3_SDP: 5.32 kWh\n",
      "28. witel - Lantai3_AHU: 5.20 kWh\n",
      "29. witel - lantai3_ahu: 5.20 kWh\n",
      "30. witel - lantai2_ahu: 4.98 kWh\n",
      "31. witel - Lantai2_AHU: 4.98 kWh\n",
      "32. witel - Lantai4_AHU: 4.79 kWh\n",
      "33. opmc - Lantai2_AHU: 3.89 kWh\n",
      "34. witel - Lantai8_SDP: 3.44 kWh\n",
      "35. opmc - Lantai4_SDP: 2.59 kWh\n",
      "36. witel - Lantai4_SDP: 2.59 kWh\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: OPMC_SDP\n",
      "==================================================\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung/opmc/sdp\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=26747, Validasi=5731, Uji=5732 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "WARNING:tensorflow:5 out of the last 82 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fb28152e700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "   - Plot prediksi untuk grup 'opmc_sdp' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah GradientBoosting (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: OPMC_AHU\n",
      "==================================================\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung/opmc/ahu\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Temperature', 'Relative Humidity', 'Evapotranspiration', 'Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=11333, Validasi=2428, Uji=2429 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "   - Plot prediksi untuk grup 'opmc_ahu' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah RandomForest (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: OPMC_LIFT\n",
      "==================================================\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung/opmc/lift\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Temperature', 'Relative Humidity', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Speed', 'Wind Gusts', 'Sunshine Duration', 'UV Index', 'Direct Radiation', 'Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=704, Validasi=151, Uji=152 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "   - Plot prediksi untuk grup 'opmc_lift' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah GradientBoosting (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: WITEL_AHU\n",
      "==================================================\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung/witel/ahu\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Temperature', 'Relative Humidity', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Sunshine Duration', 'UV Index', 'Direct Radiation', 'Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=37868, Validasi=8115, Uji=8115 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "   - Plot prediksi untuk grup 'witel_ahu' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah RandomForest (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: WITEL_SDP\n",
      "==================================================\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung/witel/sdp\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=48191, Validasi=10327, Uji=10327 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "   - Plot prediksi untuk grup 'witel_sdp' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah RandomForest (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: WITEL_LIFT\n",
      "==================================================\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung/witel/lift\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Temperature', 'Relative Humidity', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'Sunshine Duration', 'UV Index', 'Direct Radiation', 'Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=8368, Validasi=1793, Uji=1794 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "   - Plot prediksi untuk grup 'witel_lift' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah RandomForest (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: WITEL_CHILLER\n",
      "==================================================\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung/witel/chiller\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=704, Validasi=151, Uji=152 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "   - Plot prediksi untuk grup 'witel_chiller' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah RandomForest (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Ringkasan Model Terbaik (dari 7 grup perangkat)\n",
      "==================================================\n",
      "🏆 RandomForest: Model terbaik sebanyak 5/7 kali (71.4%)\n",
      "🏆 GradientBoosting: Model terbaik sebanyak 2/7 kali (28.6%)\n",
      "\n",
      "==================================================\n",
      "Statistik Evaluasi Keseluruhan (Rata-rata dari semua model)\n",
      "==================================================\n",
      "Rata-rata R2 Score : 0.77\n",
      "Rata-rata RMSE      : 111.53 kWh\n",
      "Rata-rata MAE       : 54.28 kWh\n",
      "\n",
      "==================================================\n",
      "Rata-Rata Metrik per Model\n",
      "==================================================\n",
      "                    r2    rmse    mae\n",
      "model                                \n",
      "GradientBoosting  0.78  102.20  48.39\n",
      "LSTM              0.72  128.86  65.53\n",
      "RandomForest      0.81  103.54  48.93\n",
      "\n",
      "==================================================\n",
      "Detail Metrik Evaluasi per Grup Perangkat\n",
      "==================================================\n",
      "\n",
      "--- Grup: OPMC_AHU ---\n",
      "  - Model: RandomForest      | R2: 0.79 | RMSE: 9.55 kWh | MAE: 5.47 kWh 🏆\n",
      "  - Model: GradientBoosting  | R2: 0.80 | RMSE: 9.33 kWh | MAE: 5.49 kWh \n",
      "  - Model: LSTM              | R2: 0.78 | RMSE: 9.87 kWh | MAE: 6.45 kWh \n",
      "\n",
      "--- Grup: OPMC_LIFT ---\n",
      "  - Model: RandomForest      | R2: 0.80 | RMSE: 312.75 kWh | MAE: 140.52 kWh \n",
      "  - Model: GradientBoosting  | R2: 0.83 | RMSE: 290.77 kWh | MAE: 132.57 kWh 🏆\n",
      "  - Model: LSTM              | R2: 0.68 | RMSE: 393.11 kWh | MAE: 186.05 kWh \n",
      "\n",
      "--- Grup: OPMC_SDP ---\n",
      "  - Model: RandomForest      | R2: 0.79 | RMSE: 5.63 kWh | MAE: 3.17 kWh \n",
      "  - Model: GradientBoosting  | R2: 0.81 | RMSE: 5.31 kWh | MAE: 2.96 kWh 🏆\n",
      "  - Model: LSTM              | R2: 0.81 | RMSE: 5.36 kWh | MAE: 3.15 kWh \n",
      "\n",
      "--- Grup: WITEL_AHU ---\n",
      "  - Model: RandomForest      | R2: 0.92 | RMSE: 4.04 kWh | MAE: 1.87 kWh 🏆\n",
      "  - Model: GradientBoosting  | R2: 0.85 | RMSE: 5.38 kWh | MAE: 2.97 kWh \n",
      "  - Model: LSTM              | R2: 0.83 | RMSE: 5.78 kWh | MAE: 3.32 kWh \n",
      "\n",
      "--- Grup: WITEL_CHILLER ---\n",
      "  - Model: RandomForest      | R2: 0.70 | RMSE: 378.23 kWh | MAE: 184.91 kWh 🏆\n",
      "  - Model: GradientBoosting  | R2: 0.69 | RMSE: 388.47 kWh | MAE: 186.23 kWh \n",
      "  - Model: LSTM              | R2: 0.54 | RMSE: 471.32 kWh | MAE: 251.03 kWh \n",
      "\n",
      "--- Grup: WITEL_LIFT ---\n",
      "  - Model: RandomForest      | R2: 0.87 | RMSE: 3.12 kWh | MAE: 1.88 kWh 🏆\n",
      "  - Model: GradientBoosting  | R2: 0.69 | RMSE: 4.73 kWh | MAE: 3.30 kWh \n",
      "  - Model: LSTM              | R2: 0.66 | RMSE: 4.97 kWh | MAE: 3.44 kWh \n",
      "\n",
      "--- Grup: WITEL_SDP ---\n",
      "  - Model: RandomForest      | R2: 0.77 | RMSE: 11.45 kWh | MAE: 4.67 kWh 🏆\n",
      "  - Model: GradientBoosting  | R2: 0.77 | RMSE: 11.41 kWh | MAE: 5.19 kWh \n",
      "  - Model: LSTM              | R2: 0.76 | RMSE: 11.62 kWh | MAE: 5.25 kWh \n",
      "\n",
      "==================================================\n",
      "Membuat Plot Gabungan per Gedung\n",
      "==================================================\n",
      "✅ Plot prediksi gabungan untuk gedung 'opmc' disimpan di: hasil_model_aggregate_pergedung/opmc\n",
      "✅ Plot prediksi gabungan untuk gedung 'witel' disimpan di: hasil_model_aggregate_pergedung/witel\n",
      "\n",
      "\n",
      "🏁 Proses Selesai. Semua hasil telah disimpan di folder 'hasil_model_aggregate_pergedung'.\n"
     ]
    }
   ],
   "source": [
    "# ==\"\"\"\n",
    "# ==============================================================================\n",
    "# @title 1. Instalasi dan Impor Library\n",
    "# ==============================================================================\n",
    "# Jalankan sel ini terlebih dahulu untuk mengimpor semua library yang dibutuhkan.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"✅ Library berhasil diimpor.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 2. Konfigurasi Utama\n",
    "# ==============================================================================\n",
    "# Sel ini mendefinisikan variabel-variabel penting seperti lokasi folder\n",
    "# dan daftar kolom yang akan digunakan dalam model.\n",
    "\n",
    "# Tentukan path folder sumber data dan folder untuk menyimpan hasil\n",
    "SOURCE_DATA_DIR = 'sumber_data'\n",
    "# PEMBARUAN: Mengubah nama folder hasil\n",
    "RESULTS_DIR = 'hasil_model_aggregate_pergedung'\n",
    "\n",
    "# Pastikan folder hasil utama dan folder sumber ada\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(SOURCE_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Daftar kolom fitur yang akan digunakan (tanpa 'Apparent Temperature')\n",
    "RELEVANT_COLUMNS = [\n",
    "    'Konsumsi Energi', 'Temperature', 'Showers', 'Cloud Cover', 'Weather Code',\n",
    "    'Relative Humidity', 'Dew Point', 'Precipitation',\n",
    "    'Pressure MSL', 'Surface Pressure', 'Evapotranspiration',\n",
    "    'Vapour Pressure Deficit', 'Wind Speed', 'Wind Direction', 'Wind Gusts',\n",
    "    'Soil Temperature', 'Sunshine Duration', 'UV Index', 'Direct Radiation'\n",
    "]\n",
    "TARGET_VARIABLE = 'Konsumsi Energi'\n",
    "# MINIMUM_ROWS = 3000 # Batas minimum data untuk melatih model\n",
    "MINIMUM_ROWS = 500 # Batas minimum data untuk melatih model (diubah untuk pengujian)\n",
    "\n",
    "print(f\"📁 Folder sumber data diatur ke: '{SOURCE_DATA_DIR}'\")\n",
    "print(f\"📁 Folder hasil akan disimpan di: '{RESULTS_DIR}'\")\n",
    "print(f\"📊 Batas minimum data untuk pelatihan: {MINIMUM_ROWS} baris\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 3. Persiapan Folder dan Unggah Data\n",
    "# ==============================================================================\n",
    "# PENTING: Sebelum menjalankan sel-sel berikutnya, unggah data Anda.\n",
    "#\n",
    "# 1. Di panel file sebelah kiri Google Colab, Anda akan melihat folder 'sumber_data'.\n",
    "# 2. Klik kanan pada folder 'sumber_data' tersebut dan pilih 'Upload'.\n",
    "# 3. Unggah folder 'witel' dan 'opmc' Anda yang berisi semua data CSV\n",
    "#    ke dalam folder 'sumber_data'.\n",
    "#\n",
    "# Setelah selesai, Anda bisa melanjutkan menjalankan sel-sel berikutnya.\n",
    "\n",
    "print(\"✅ Sel ini siap.\")\n",
    "print(f\"Pastikan Anda telah mengunggah data Anda ke dalam folder '{SOURCE_DATA_DIR}'.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 4. Definisi Fungsi-Fungsi Pembantu\n",
    "# ==============================================================================\n",
    "# Sel ini berisi fungsi-fungsi utama untuk melatih model dan membuat visualisasi.\n",
    "# Jalankan sel ini untuk mendefinisikan fungsi agar bisa digunakan nanti.\n",
    "\n",
    "def train_and_evaluate_models(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melatih semua model (RF, GB, LSTM) dan mengembalikan\n",
    "    prediksi serta metrik kinerjanya.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # --- Model 1: Random Forest Regressor ---\n",
    "    print(\"   - Melatih Random Forest...\")\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    results['RandomForest'] = {'model': rf_model, 'predictions': y_pred_rf, 'mae': mean_absolute_error(y_test, y_pred_rf), 'rmse': np.sqrt(mean_squared_error(y_test, y_pred_rf)), 'r2': r2_score(y_test, y_pred_rf)}\n",
    "\n",
    "    # --- Model 2: Gradient Boosting Regressor ---\n",
    "    print(\"   - Melatih Gradient Boosting...\")\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    y_pred_gb = gb_model.predict(X_test)\n",
    "    results['GradientBoosting'] = {'model': gb_model, 'predictions': y_pred_gb, 'mae': mean_absolute_error(y_test, y_pred_gb), 'rmse': np.sqrt(mean_squared_error(y_test, y_pred_gb)), 'r2': r2_score(y_test, y_pred_gb)}\n",
    "\n",
    "    # --- Model 3: LSTM ---\n",
    "    print(\"   - Melatih LSTM...\")\n",
    "    scaler_X = MinMaxScaler(feature_range=(0, 1)); scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train); y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "    X_val_scaled = scaler_X.transform(X_val); y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1))\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "    X_val_lstm = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
    "    X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "    lstm_model = Sequential([LSTM(50, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])), Dense(1)])\n",
    "    lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    lstm_model.fit(X_train_lstm, y_train_scaled, epochs=50, batch_size=32, validation_data=(X_val_lstm, y_val_scaled), verbose=0, shuffle=False)\n",
    "    y_pred_lstm_scaled = lstm_model.predict(X_test_lstm)\n",
    "    y_pred_lstm = scaler_y.inverse_transform(y_pred_lstm_scaled)\n",
    "    results['LSTM'] = {'model': lstm_model, 'predictions': y_pred_lstm.flatten(), 'mae': mean_absolute_error(y_test, y_pred_lstm), 'rmse': np.sqrt(mean_squared_error(y_test, y_pred_lstm)), 'r2': r2_score(y_test, y_pred_lstm)}\n",
    "    return results\n",
    "\n",
    "def create_prediction_plots(y_test, predictions, plot_suffix, output_dir):\n",
    "    \"\"\"Membuat dan menyimpan scatter plot dan line graph untuk prediksi.\"\"\"\n",
    "    # --- Konversi ke kWh untuk semua plot ---\n",
    "    y_test_kwh = y_test / 1000\n",
    "    predictions_kwh = {name: pred / 1000 for name, pred in predictions.items()}\n",
    "\n",
    "    # --- Scatter Plot (Semua Data Test) ---\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    colors = ['green', 'red', 'orange']\n",
    "    for i, (model_name, pred_kwh) in enumerate(predictions_kwh.items()):\n",
    "        mae_kwh = mean_absolute_error(y_test_kwh, pred_kwh)\n",
    "        rmse_kwh = np.sqrt(mean_squared_error(y_test_kwh, pred_kwh))\n",
    "        r2 = r2_score(y_test_kwh, pred_kwh)\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.scatter(y_test_kwh, pred_kwh, alpha=0.6, edgecolors='k', color=colors[i])\n",
    "        plt.plot([y_test_kwh.min(), y_test_kwh.max()], [y_test_kwh.min(), y_test_kwh.max()], '--r', linewidth=2)\n",
    "        plt.title(f'{model_name}\\nR2: {r2:.2f} | RMSE: {rmse_kwh:.2f} | MAE: {mae_kwh:.2f} kWh')\n",
    "        plt.xlabel('Nilai Aktual (kWh)')\n",
    "        plt.ylabel('Nilai Prediksi (kWh)')\n",
    "        plt.grid(True)\n",
    "    plt.suptitle(f'Scatter Plot (Semua Data Test) - {plot_suffix}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(os.path.join(output_dir, f'scatter_plot_{plot_suffix}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # --- Persiapan DataFrame untuk Plot Zoom ---\n",
    "    plot_df_full = pd.DataFrame({'Aktual (kWh)': y_test_kwh})\n",
    "    for model_name, pred_kwh in predictions_kwh.items():\n",
    "        plot_df_full[model_name] = pred_kwh\n",
    "    \n",
    "    # PEMBARUAN: Mengambil 500 data terakhir untuk zoom\n",
    "    plot_df_zoom = plot_df_full.tail(500)\n",
    "\n",
    "    # --- Scatter Plot Zoom (500 Data Terakhir) ---\n",
    "    if not plot_df_zoom.empty:\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        for i, model_name in enumerate(predictions_kwh.keys()):\n",
    "            y_test_zoom = plot_df_zoom['Aktual (kWh)']\n",
    "            pred_zoom = plot_df_zoom[model_name]\n",
    "            mae_kwh = mean_absolute_error(y_test_zoom, pred_zoom)\n",
    "            rmse_kwh = np.sqrt(mean_squared_error(y_test_zoom, pred_zoom))\n",
    "            r2 = r2_score(y_test_zoom, pred_zoom)\n",
    "            plt.subplot(1, 3, i + 1)\n",
    "            plt.scatter(y_test_zoom, pred_zoom, alpha=0.6, edgecolors='k', color=colors[i])\n",
    "            plt.plot([y_test_zoom.min(), y_test_zoom.max()], [y_test_zoom.min(), y_test_zoom.max()], '--r', linewidth=2)\n",
    "            plt.title(f'{model_name}\\nR2: {r2:.2f} | RMSE: {rmse_kwh:.2f} | MAE: {mae_kwh:.2f} kWh')\n",
    "            plt.xlabel('Nilai Aktual (kWh)')\n",
    "            plt.ylabel('Nilai Prediksi (kWh)')\n",
    "            plt.grid(True)\n",
    "        plt.suptitle(f'Scatter Plot Zoom (100 Data Terakhir) - {plot_suffix}', fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.savefig(os.path.join(output_dir, f'scatter_plot_zoom_{plot_suffix}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    # --- Grafik Waktu (Titik Acak) ---\n",
    "    plot_df_full.sort_index(inplace=True)\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(plot_df_full.index, plot_df_full['Aktual (kWh)'], label='Nilai Aktual', color='blue', marker='o', linestyle='None', markersize=5, alpha=0.8)\n",
    "    plt.plot(plot_df_full.index, plot_df_full['RandomForest'], label='Prediksi RF', color='green', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "    plt.plot(plot_df_full.index, plot_df_full['GradientBoosting'], label='Prediksi GB', color='red', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "    plt.plot(plot_df_full.index, plot_df_full['LSTM'], label='Prediksi LSTM', color='orange', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "    plt.title(f'Grafik Waktu: Prediksi vs Aktual - {plot_suffix}\\n(Menampilkan titik data dari Test Set yang acak)', fontsize=16)\n",
    "    plt.xlabel('Waktu'); plt.ylabel('Konsumsi Energi (kWh)')\n",
    "    plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'time_series_plot_{plot_suffix}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # --- Grafik Waktu Zoom (100 Data Terakhir) ---\n",
    "    if not plot_df_zoom.empty:\n",
    "        plt.figure(figsize=(20, 8))\n",
    "        plt.plot(plot_df_zoom.index, plot_df_zoom['Aktual (kWh)'], label='Nilai Aktual', color='blue', marker='o', linestyle='None', markersize=5, alpha=0.8)\n",
    "        plt.plot(plot_df_zoom.index, plot_df_zoom['RandomForest'], label='Prediksi RF', color='green', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "        plt.plot(plot_df_zoom.index, plot_df_zoom['GradientBoosting'], label='Prediksi GB', color='red', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "        plt.plot(plot_df_zoom.index, plot_df_zoom['LSTM'], label='Prediksi LSTM', color='orange', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "        plt.title(f'Grafik Waktu Zoom (100 Data Terakhir) - {plot_suffix}', fontsize=16)\n",
    "        plt.xlabel('Waktu'); plt.ylabel('Konsumsi Energi (kWh)')\n",
    "        plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'time_series_plot_zoom_{plot_suffix}.png'))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def create_combined_heatmap(performance_data, title_suffix, output_dir):\n",
    "    \"\"\"Membuat dan menyimpan heatmap gabungan dari data kinerja model.\"\"\"\n",
    "    if not performance_data:\n",
    "        print(f\"Tidak ada data kinerja untuk membuat heatmap.\")\n",
    "        return\n",
    "    df = pd.DataFrame(performance_data)\n",
    "    \n",
    "    df['Label Perangkat'] = df['Gedung'] + ' - ' + df['Perangkat']\n",
    "    try:\n",
    "        df.sort_values(by=['Gedung', 'Label Perangkat'], inplace=True)\n",
    "        mae_pivot = df.pivot_table(index='Model', columns='Label Perangkat', values='MAE')\n",
    "        rmse_pivot = df.pivot_table(index='Model', columns='Label Perangkat', values='RMSE')\n",
    "        r2_pivot = df.pivot_table(index='Model', columns='Label Perangkat', values='R2')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat membuat pivot table untuk {title_suffix}: {e}\\nData: {df}\")\n",
    "        return\n",
    "        \n",
    "    num_devices = len(df['Label Perangkat'].unique())\n",
    "    fig_width = max(18, num_devices * 1.5)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(fig_width, 21))\n",
    "    fig.suptitle(f'Heatmap Kinerja Model - {title_suffix}', fontsize=20)\n",
    "    \n",
    "    # Heatmap R2\n",
    "    sns.heatmap(r2_pivot, annot=True, fmt=\".2f\", cmap=\"viridis\", ax=axes[0], linewidths=.5)\n",
    "    axes[0].set_title('R2 Score - Lebih Tinggi Lebih Baik', fontsize=16)\n",
    "    axes[0].set_xlabel(''); axes[0].set_ylabel('Model', fontsize=12)\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Heatmap RMSE\n",
    "    sns.heatmap(rmse_pivot, annot=True, fmt=\".2f\", cmap=\"viridis_r\", ax=axes[1], linewidths=.5)\n",
    "    axes[1].set_title('RMSE (kWh) - Lebih Rendah Lebih Baik', fontsize=16)\n",
    "    axes[1].set_xlabel(''); axes[1].set_ylabel('Model', fontsize=12)\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Heatmap MAE\n",
    "    sns.heatmap(mae_pivot, annot=True, fmt=\".2f\", cmap=\"viridis_r\", ax=axes[2], linewidths=.5)\n",
    "    axes[2].set_title('MAE (kWh) - Lebih Rendah Lebih Baik', fontsize=16)\n",
    "    axes[2].set_xlabel('Gedung - Perangkat / Lokasi', fontsize=12)\n",
    "    axes[2].set_ylabel('Model', fontsize=12)\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    heatmap_path = os.path.join(output_dir, f'heatmap_{title_suffix}.png')\n",
    "    plt.savefig(heatmap_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"\\nHeatmap gabungan disimpan di: {heatmap_path}\")\n",
    "\n",
    "print(\"✅ Fungsi-fungsi pembantu berhasil didefinisikan.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 5. Memuat, Membersihkan, dan Menggabungkan Data\n",
    "# ==============================================================================\n",
    "# Sel ini akan memuat semua data, membersihkannya, dan menggabungkannya\n",
    "# berdasarkan jenis perangkat di setiap gedung.\n",
    "\n",
    "grouped_data = {}\n",
    "consumption_ranking = []\n",
    "\n",
    "print(\"Memulai proses pemuatan dan penggabungan data...\")\n",
    "for root, dirs, files in os.walk(SOURCE_DATA_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, index_col='id_time', parse_dates=True)\n",
    "                \n",
    "                if TARGET_VARIABLE not in df.columns or df[TARGET_VARIABLE].isnull().all():\n",
    "                    continue\n",
    "                \n",
    "                df_cleaned = df[[TARGET_VARIABLE]].dropna()\n",
    "                df_cleaned = df_cleaned[df_cleaned[TARGET_VARIABLE] > 0]\n",
    "\n",
    "                if not df_cleaned.empty:\n",
    "                    path_parts = os.path.relpath(root, SOURCE_DATA_DIR).split(os.sep)\n",
    "                    building = path_parts[0]\n",
    "                    device_label = \"_\".join(path_parts[1:])\n",
    "                    avg_consumption = df_cleaned[TARGET_VARIABLE].mean()\n",
    "                    consumption_ranking.append({\n",
    "                        'label': f\"{building} - {device_label}\",\n",
    "                        'avg_kwh': avg_consumption / 1000\n",
    "                    })\n",
    "\n",
    "                path_parts = os.path.relpath(root, SOURCE_DATA_DIR).split(os.sep)\n",
    "                building = path_parts[0]\n",
    "                device_type = path_parts[-1].split('_')[0].lower()\n",
    "                \n",
    "                group_key = f\"{building}_{device_type}\"\n",
    "                \n",
    "                if group_key not in grouped_data:\n",
    "                    grouped_data[group_key] = []\n",
    "                \n",
    "                grouped_data[group_key].append(df)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   - Gagal memproses {file_path}: {e}\")\n",
    "\n",
    "for key, df_list in grouped_data.items():\n",
    "    grouped_data[key] = pd.concat(df_list, ignore_index=False)\n",
    "    print(f\"✅ Data untuk '{key}' berhasil digabungkan, total {len(grouped_data[key])} baris.\")\n",
    "\n",
    "print(\"\\n--- Peringkat Konsumsi Energi Rata-Rata Terbesar ---\")\n",
    "consumption_ranking.sort(key=lambda x: x['avg_kwh'], reverse=True)\n",
    "for i, item in enumerate(consumption_ranking):\n",
    "    print(f\"{i+1}. {item['label']}: {item['avg_kwh']:.2f} kWh\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 6. Proses Utama: Melatih Model per Jenis Perangkat\n",
    "# ==============================================================================\n",
    "# Sel ini akan melakukan loop melalui data yang sudah digabungkan,\n",
    "# melatih model, dan menyimpan hasilnya.\n",
    "\n",
    "best_model_counter = Counter()\n",
    "all_model_stats = []\n",
    "total_models_trained = 0\n",
    "building_predictions_tracker = {}\n",
    "\n",
    "\n",
    "for group_name, df_group in grouped_data.items():\n",
    "    print(f\"\\n{'='*50}\\nMemproses Grup: {group_name.upper()}\\n{'='*50}\")\n",
    "    \n",
    "    existing_cols = [col for col in RELEVANT_COLUMNS if col in df_group.columns]\n",
    "    df_processed = df_group.reindex(columns=existing_cols).copy()\n",
    "    df_processed.dropna(subset=[TARGET_VARIABLE], inplace=True)\n",
    "    \n",
    "    for lag in range(1, 4):\n",
    "        df_processed[f'Konsumsi_Energi_Lag_{lag}'] = df_processed[TARGET_VARIABLE].shift(lag)\n",
    "    \n",
    "    df_processed.dropna(inplace=True)\n",
    "    df_final = df_processed[df_processed[TARGET_VARIABLE] > 0].copy()\n",
    "\n",
    "    if len(df_final) < MINIMUM_ROWS:\n",
    "        print(f\"   - ⚠️ PERINGATAN: Data tidak cukup ({len(df_final)} baris). Melewati pelatihan untuk grup ini.\")\n",
    "        continue\n",
    "\n",
    "    print(\"   - Menghitung matriks korelasi...\")\n",
    "    correlation_matrix = df_final.corr()\n",
    "    \n",
    "    output_dir = os.path.join(RESULTS_DIR, *group_name.split('_'))\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(22, 18))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "    plt.title(f'Correlation Matrix - {group_name}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'correlation_matrix_{group_name}.png'))\n",
    "    plt.close()\n",
    "    print(f\"   - Heatmap korelasi disimpan di: {output_dir}\")\n",
    "\n",
    "    correlations = correlation_matrix[TARGET_VARIABLE].abs()\n",
    "    selected_features = correlations[correlations >= 0.4].index.tolist()\n",
    "    features_for_model = [f for f in selected_features if f != TARGET_VARIABLE]\n",
    "\n",
    "    print(f\"   - Fitur terpilih dengan korelasi >= 0.4: {features_for_model}\")\n",
    "    if not features_for_model:\n",
    "        print(\"   - Tidak ada fitur yang memenuhi ambang korelasi.\"); continue\n",
    "\n",
    "    X = df_final[features_for_model]; y = df_final[TARGET_VARIABLE]\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    if len(X_train) == 0 or len(X_test) == 0: continue\n",
    "\n",
    "    print(f\"   - Ukuran Data: Latih={len(X_train)}, Validasi={len(X_val)}, Uji={len(X_test)} (Acak)\")\n",
    "    model_evaluations = train_and_evaluate_models(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    \n",
    "    device_predictions = {name: data['predictions'] for name, data in model_evaluations.items()}\n",
    "    create_prediction_plots(y_test, device_predictions, group_name, output_dir)\n",
    "    print(f\"   - Plot prediksi untuk grup '{group_name}' disimpan.\")\n",
    "\n",
    "    building_name = group_name.split('_')[0]\n",
    "    if building_name not in building_predictions_tracker:\n",
    "        building_predictions_tracker[building_name] = {'y_true': [], 'preds': {'RandomForest': [], 'GradientBoosting': [], 'LSTM': []}}\n",
    "\n",
    "    building_predictions_tracker[building_name]['y_true'].append(y_test)\n",
    "    for model_name, preds in device_predictions.items():\n",
    "        building_predictions_tracker[building_name]['preds'][model_name].append(preds)\n",
    "\n",
    "    best_model_name, best_model_mae = '', float('inf')\n",
    "    for model_name, eval_data in model_evaluations.items():\n",
    "        if eval_data['mae'] < best_model_mae:\n",
    "            best_model_mae = eval_data['mae']\n",
    "            best_model_name = model_name\n",
    "        \n",
    "        all_model_stats.append({\n",
    "            'group': group_name,\n",
    "            'model': model_name,\n",
    "            'mae': eval_data['mae'] / 1000,\n",
    "            'rmse': eval_data['rmse'] / 1000,\n",
    "            'r2': eval_data['r2']\n",
    "        })\n",
    "    \n",
    "    best_model_counter[best_model_name] += 1\n",
    "    total_models_trained += 1\n",
    "    print(f\"   ==> Model terbaik untuk grup ini adalah {best_model_name} (berdasarkan MAE).\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 7. Ringkasan dan Analisis Final\n",
    "# ==============================================================================\n",
    "# Sel ini akan menampilkan ringkasan model terbaik dan statistik evaluasi.\n",
    "\n",
    "if total_models_trained > 0:\n",
    "    stats_df = pd.DataFrame(all_model_stats)\n",
    "\n",
    "    # --- 1. Ringkasan Model Terbaik ---\n",
    "    print(f\"\\n{'='*50}\\nRingkasan Model Terbaik (dari {total_models_trained} grup perangkat)\\n{'='*50}\")\n",
    "    sorted_models = best_model_counter.most_common()\n",
    "    for model, count in sorted_models:\n",
    "        percentage = (count / total_models_trained) * 100\n",
    "        print(f\"🏆 {model}: Model terbaik sebanyak {count}/{total_models_trained} kali ({percentage:.1f}%)\")\n",
    "\n",
    "    # --- 2. Statistik Evaluasi Keseluruhan ---\n",
    "    print(f\"\\n{'='*50}\\nStatistik Evaluasi Keseluruhan (Rata-rata dari semua model)\\n{'='*50}\")\n",
    "    overall_avg = stats_df[['r2', 'rmse', 'mae']].mean()\n",
    "    print(f\"Rata-rata R2 Score : {overall_avg['r2']:.2f}\")\n",
    "    print(f\"Rata-rata RMSE      : {overall_avg['rmse']:.2f} kWh\")\n",
    "    print(f\"Rata-rata MAE       : {overall_avg['mae']:.2f} kWh\")\n",
    "\n",
    "    # --- 3. Rata-Rata Metrik per Model ---\n",
    "    print(f\"\\n{'='*50}\\nRata-Rata Metrik per Model\\n{'='*50}\")\n",
    "    per_model_avg = stats_df.groupby('model')[['r2', 'rmse', 'mae']].mean()\n",
    "    print(per_model_avg.round(2))\n",
    "    \n",
    "    # --- 4. Detail Metrik Evaluasi per Grup Perangkat ---\n",
    "    print(f\"\\n{'='*50}\\nDetail Metrik Evaluasi per Grup Perangkat\\n{'='*50}\")\n",
    "    for group, group_df in stats_df.groupby('group'):\n",
    "        print(f\"\\n--- Grup: {group.upper()} ---\")\n",
    "        best_model_in_group = group_df.loc[group_df['mae'].idxmin()]\n",
    "        for index, row in group_df.iterrows():\n",
    "            is_best = \"🏆\" if row['model'] == best_model_in_group['model'] else \"\"\n",
    "            print(f\"  - Model: {row['model']:<17} | R2: {row['r2']:.2f} | RMSE: {row['rmse']:.2f} kWh | MAE: {row['mae']:.2f} kWh {is_best}\")\n",
    "\n",
    "    # --- 5. Membuat Plot Gabungan per Gedung ---\n",
    "    print(f\"\\n{'='*50}\\nMembuat Plot Gabungan per Gedung\\n{'='*50}\")\n",
    "    for building_name, data in building_predictions_tracker.items():\n",
    "        y_true_combined = pd.concat(data['y_true'])\n",
    "        preds_combined = {model: np.concatenate(preds) for model, preds in data['preds'].items()}\n",
    "        \n",
    "        building_output_dir = os.path.join(RESULTS_DIR, building_name)\n",
    "        os.makedirs(building_output_dir, exist_ok=True)\n",
    "        \n",
    "        create_prediction_plots(y_true_combined, preds_combined, f\"Gabungan_{building_name.upper()}\", building_output_dir)\n",
    "        print(f\"✅ Plot prediksi gabungan untuk gedung '{building_name}' disimpan di: {building_output_dir}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nTidak ada model yang dilatih, ringkasan tidak dapat dibuat.\")\n",
    "\n",
    "print(f\"\\n\\n🏁 Proses Selesai. Semua hasil telah disimpan di folder '{RESULTS_DIR}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c15653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Library berhasil diimpor.\n",
      "📁 Folder sumber data diatur ke: 'sumber_data'\n",
      "📁 Folder hasil akan disimpan di: 'hasil_model_aggregate_pergedung_revisikorelasimatrix'\n",
      "📊 Batas minimum data untuk pelatihan: 500 baris\n",
      "✅ Sel ini siap.\n",
      "Pastikan Anda telah mengunggah data Anda ke dalam folder 'sumber_data'.\n",
      "✅ Fungsi-fungsi pembantu berhasil didefinisikan.\n",
      "Memulai proses pemuatan dan penggabungan data...\n",
      "✅ Data untuk 'opmc_sdp' berhasil digabungkan, total 52674 baris.\n",
      "✅ Data untuk 'opmc_ahu' berhasil digabungkan, total 43893 baris.\n",
      "✅ Data untuk 'opmc_lift' berhasil digabungkan, total 1121 baris.\n",
      "✅ Data untuk 'witel_ahu' berhasil digabungkan, total 96391 baris.\n",
      "✅ Data untuk 'witel_sdp' berhasil digabungkan, total 96598 baris.\n",
      "✅ Data untuk 'witel_lift' berhasil digabungkan, total 17554 baris.\n",
      "✅ Data untuk 'witel_chiller' berhasil digabungkan, total 1121 baris.\n",
      "\n",
      "--- Peringkat Konsumsi Energi Rata-Rata Terbesar ---\n",
      "1. opmc - LIFT: 326.63 kWh\n",
      "2. witel - CHILLER: 326.63 kWh\n",
      "3. witel - Lantai7_SDP: 57.95 kWh\n",
      "4. witel - Lantai7_AHU: 35.70 kWh\n",
      "5. witel - Lantai6_SDP: 35.65 kWh\n",
      "6. witel - Lantai8_AHU: 35.06 kWh\n",
      "7. witel - Lantai6_AHU: 31.47 kWh\n",
      "8. opmc - Lantai5_AHU: 29.07 kWh\n",
      "9. witel - lantai1_sdp: 24.09 kWh\n",
      "10. witel - Lantai1_SDP: 24.09 kWh\n",
      "11. opmc - Lantai6_SDP: 23.63 kWh\n",
      "12. opmc - Lantai3_AHU: 22.52 kWh\n",
      "13. witel - lift: 20.16 kWh\n",
      "14. witel - LIFT: 20.16 kWh\n",
      "15. opmc - Lantai5_SDP: 18.59 kWh\n",
      "16. witel - lantai1_ahu: 17.54 kWh\n",
      "17. witel - Lantai1_AHU: 17.54 kWh\n",
      "18. witel - Lantai3_SDP: 16.32 kWh\n",
      "19. witel - lantai3_sdp: 16.32 kWh\n",
      "20. opmc - Lantai1_SDP: 15.65 kWh\n",
      "21. opmc - Lantai4_AHU: 13.23 kWh\n",
      "22. witel - lantai2_sdp: 13.12 kWh\n",
      "23. witel - Lantai2_SDP: 13.12 kWh\n",
      "24. witel - Lantai5_SDP: 12.35 kWh\n",
      "25. witel - Lantai5_AHU: 12.31 kWh\n",
      "26. opmc - Lantai2_SDP: 7.98 kWh\n",
      "27. opmc - Lantai3_SDP: 5.32 kWh\n",
      "28. witel - Lantai3_AHU: 5.20 kWh\n",
      "29. witel - lantai3_ahu: 5.20 kWh\n",
      "30. witel - lantai2_ahu: 4.98 kWh\n",
      "31. witel - Lantai2_AHU: 4.98 kWh\n",
      "32. witel - Lantai4_AHU: 4.79 kWh\n",
      "33. opmc - Lantai2_AHU: 3.89 kWh\n",
      "34. witel - Lantai8_SDP: 3.44 kWh\n",
      "35. opmc - Lantai4_SDP: 2.59 kWh\n",
      "36. witel - Lantai4_SDP: 2.59 kWh\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: OPMC_SDP\n",
      "==================================================\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix/opmc/sdp\n",
      "   - Tahap 1: Ditemukan 9 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'Sunshine Duration', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 9 fitur independen yang tersisa.\n",
      "   - Tahap 2: Tidak ditemukan fitur dengan korelasi |r| >= 0.4. Menurunkan threshold ke 0.3...\n",
      "   - Tahap 2 (Revisi): Ditemukan 1 fitur dengan korelasi |r| >= 0.3: ['Temperature']\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1', 'Temperature']\n",
      "\n",
      "   - Ukuran Data: Latih=26748, Validasi=5732, Uji=5732 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "   - Plot prediksi untuk grup 'opmc_sdp' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah GradientBoosting (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: OPMC_AHU\n",
      "==================================================\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix/opmc/ahu\n",
      "   - Tahap 1: Ditemukan 9 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'Sunshine Duration', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 9 fitur independen yang tersisa.\n",
      "   - Tahap 2: Ditemukan 1 fitur independen yang berkorelasi kuat dengan target (|r| >= 0.4): ['Temperature']\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1', 'Temperature']\n",
      "\n",
      "   - Ukuran Data: Latih=11334, Validasi=2429, Uji=2429 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "   - Plot prediksi untuk grup 'opmc_ahu' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah GradientBoosting (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: OPMC_LIFT\n",
      "==================================================\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix/opmc/lift\n",
      "   - Tahap 1: Ditemukan 8 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 10 fitur independen yang tersisa.\n",
      "   - Tahap 2: Tidak ditemukan fitur dengan korelasi |r| >= 0.4. Menurunkan threshold ke 0.3...\n",
      "   - Tahap 2 (Revisi): Ditemukan 3 fitur dengan korelasi |r| >= 0.3: ['Temperature', 'Wind Speed', 'Sunshine Duration']\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1', 'Temperature', 'Wind Speed', 'Sunshine Duration']\n",
      "\n",
      "   - Ukuran Data: Latih=706, Validasi=151, Uji=152 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "   - Plot prediksi untuk grup 'opmc_lift' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah RandomForest (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: WITEL_AHU\n",
      "==================================================\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix/witel/ahu\n",
      "   - Tahap 1: Ditemukan 9 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'Sunshine Duration', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 9 fitur independen yang tersisa.\n",
      "   - Tahap 2: Ditemukan 1 fitur independen yang berkorelasi kuat dengan target (|r| >= 0.4): ['Temperature']\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1', 'Temperature']\n",
      "\n",
      "   - Ukuran Data: Latih=37870, Validasi=8115, Uji=8115 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "   - Plot prediksi untuk grup 'witel_ahu' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah RandomForest (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: WITEL_SDP\n",
      "==================================================\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix/witel/sdp\n",
      "   - Tahap 1: Ditemukan 9 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'Sunshine Duration', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 9 fitur independen yang tersisa.\n",
      "   - Tahap 2: Tidak ditemukan fitur dengan korelasi |r| >= 0.4. Menurunkan threshold ke 0.3...\n",
      "   - Tahap 2 (Revisi): Ditemukan 0 fitur dengan korelasi |r| >= 0.3: []\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1']\n",
      "\n",
      "   - Ukuran Data: Latih=48192, Validasi=10327, Uji=10328 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "   - Plot prediksi untuk grup 'witel_sdp' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah GradientBoosting (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: WITEL_LIFT\n",
      "==================================================\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix/witel/lift\n",
      "   - Tahap 1: Ditemukan 9 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'Sunshine Duration', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 9 fitur independen yang tersisa.\n",
      "   - Tahap 2: Ditemukan 1 fitur independen yang berkorelasi kuat dengan target (|r| >= 0.4): ['Temperature']\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1', 'Temperature']\n",
      "\n",
      "   - Ukuran Data: Latih=8369, Validasi=1794, Uji=1794 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "   - Plot prediksi untuk grup 'witel_lift' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah RandomForest (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: WITEL_CHILLER\n",
      "==================================================\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix/witel/chiller\n",
      "   - Tahap 1: Ditemukan 0 fitur dengan multikolinearitas (dihapus): []\n",
      "   - Tahap 1: Terdapat 10 fitur independen yang tersisa.\n",
      "   - Tahap 2: Tidak ditemukan fitur dengan korelasi |r| >= 0.4. Menurunkan threshold ke 0.3...\n",
      "   - Tahap 2 (Revisi): Ditemukan 0 fitur dengan korelasi |r| >= 0.3: []\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1']\n",
      "\n",
      "   - Ukuran Data: Latih=706, Validasi=151, Uji=152 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "   - Plot prediksi untuk grup 'witel_chiller' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah GradientBoosting (berdasarkan MAE).\n",
      "\n",
      "✅ Laporan kinerja lengkap disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix/laporan_kinerja_semua_model.csv\n",
      "\n",
      "==================================================\n",
      "Ringkasan Model Terbaik (dari 7 grup perangkat)\n",
      "==================================================\n",
      "🏆 GradientBoosting: Model terbaik sebanyak 4/7 kali (57.1%)\n",
      "🏆 RandomForest: Model terbaik sebanyak 3/7 kali (42.9%)\n",
      "\n",
      "==================================================\n",
      "Statistik Evaluasi Keseluruhan (Rata-rata dari semua model)\n",
      "==================================================\n",
      "Rata-rata R2 Score : 0.71\n",
      "Rata-rata RMSE     : 105.25 kWh\n",
      "Rata-rata MAE      : 46.01 kWh\n",
      "\n",
      "==================================================\n",
      "Rata-Rata Metrik per Model\n",
      "==================================================\n",
      "                    R2    RMSE    MAE\n",
      "Model                                \n",
      "GradientBoosting  0.71  104.70  45.84\n",
      "LSTM              0.70  106.05  47.51\n",
      "RandomForest      0.71  105.00  44.70\n",
      "\n",
      "==================================================\n",
      "Detail Metrik Evaluasi per Grup Perangkat\n",
      "==================================================\n",
      "\n",
      "--- Grup: OPMC - AHU ---\n",
      "  - Model: RandomForest      | R2: 0.68 | RMSE: 11.54 kWh | MAE: 6.78 kWh \n",
      "  - Model: GradientBoosting  | R2: 0.75 | RMSE: 10.27 kWh | MAE: 6.03 kWh 🏆\n",
      "  - Model: LSTM              | R2: 0.74 | RMSE: 10.51 kWh | MAE: 6.30 kWh \n",
      "\n",
      "--- Grup: OPMC - LIFT ---\n",
      "  - Model: RandomForest      | R2: 0.72 | RMSE: 307.36 kWh | MAE: 123.09 kWh 🏆\n",
      "  - Model: GradientBoosting  | R2: 0.67 | RMSE: 334.69 kWh | MAE: 140.10 kWh \n",
      "  - Model: LSTM              | R2: 0.67 | RMSE: 333.88 kWh | MAE: 131.74 kWh \n",
      "\n",
      "--- Grup: OPMC - SDP ---\n",
      "  - Model: RandomForest      | R2: 0.78 | RMSE: 5.78 kWh | MAE: 3.46 kWh \n",
      "  - Model: GradientBoosting  | R2: 0.83 | RMSE: 5.12 kWh | MAE: 2.96 kWh 🏆\n",
      "  - Model: LSTM              | R2: 0.82 | RMSE: 5.23 kWh | MAE: 3.00 kWh \n",
      "\n",
      "--- Grup: WITEL - AHU ---\n",
      "  - Model: RandomForest      | R2: 0.76 | RMSE: 6.72 kWh | MAE: 3.49 kWh 🏆\n",
      "  - Model: GradientBoosting  | R2: 0.76 | RMSE: 6.77 kWh | MAE: 3.72 kWh \n",
      "  - Model: LSTM              | R2: 0.73 | RMSE: 7.17 kWh | MAE: 4.26 kWh \n",
      "\n",
      "--- Grup: WITEL - CHILLER ---\n",
      "  - Model: RandomForest      | R2: 0.56 | RMSE: 387.16 kWh | MAE: 167.40 kWh \n",
      "  - Model: GradientBoosting  | R2: 0.62 | RMSE: 358.92 kWh | MAE: 158.67 kWh 🏆\n",
      "  - Model: LSTM              | R2: 0.60 | RMSE: 368.24 kWh | MAE: 177.36 kWh \n",
      "\n",
      "--- Grup: WITEL - LIFT ---\n",
      "  - Model: RandomForest      | R2: 0.73 | RMSE: 4.53 kWh | MAE: 3.14 kWh 🏆\n",
      "  - Model: GradientBoosting  | R2: 0.62 | RMSE: 5.38 kWh | MAE: 3.92 kWh \n",
      "  - Model: LSTM              | R2: 0.59 | RMSE: 5.57 kWh | MAE: 4.02 kWh \n",
      "\n",
      "--- Grup: WITEL - SDP ---\n",
      "  - Model: RandomForest      | R2: 0.75 | RMSE: 11.91 kWh | MAE: 5.51 kWh \n",
      "  - Model: GradientBoosting  | R2: 0.76 | RMSE: 11.75 kWh | MAE: 5.46 kWh 🏆\n",
      "  - Model: LSTM              | R2: 0.75 | RMSE: 11.78 kWh | MAE: 5.87 kWh \n",
      "\n",
      "==================================================\n",
      "Membuat Plot Gabungan per Gedung\n",
      "==================================================\n",
      "✅ Plot prediksi gabungan untuk gedung 'opmc' disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix/opmc\n",
      "✅ Plot prediksi gabungan untuk gedung 'witel' disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix/witel\n",
      "\n",
      "==================================================\n",
      "Membuat Heatmap Kinerja Gabungan\n",
      "==================================================\n",
      "\n",
      "Heatmap gabungan disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix/heatmap_Kinerja_Gabungan_Semua_Gedung.png\n",
      "\n",
      "\n",
      "🏁 Proses Selesai. Semua hasil telah disimpan di folder 'hasil_model_aggregate_pergedung_revisikorelasimatrix'.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# @title 1. Instalasi dan Impor Library\n",
    "# ==============================================================================\n",
    "# Jalankan sel ini terlebih dahulu untuk mengimpor semua library yang dibutuhkan.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"✅ Library berhasil diimpor.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 2. Konfigurasi Utama\n",
    "# ==============================================================================\n",
    "# Sel ini mendefinisikan variabel-variabel penting seperti lokasi folder\n",
    "# dan daftar kolom yang akan digunakan dalam model.\n",
    "\n",
    "# Tentukan path folder sumber data dan folder untuk menyimpan hasil\n",
    "SOURCE_DATA_DIR = 'sumber_data'\n",
    "# PEMBARUAN: Mengubah nama folder hasil\n",
    "RESULTS_DIR = 'hasil_model_aggregate_pergedung_revisikorelasimatrix'\n",
    "\n",
    "# Pastikan folder hasil utama dan folder sumber ada\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(SOURCE_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Daftar kolom fitur yang akan digunakan (tanpa 'Apparent Temperature')\n",
    "RELEVANT_COLUMNS = [\n",
    "    'Konsumsi Energi', 'Temperature', 'Showers', 'Cloud Cover', 'Weather Code',\n",
    "    'Relative Humidity', 'Dew Point', 'Precipitation',\n",
    "    'Pressure MSL', 'Surface Pressure', 'Evapotranspiration',\n",
    "    'Vapour Pressure Deficit', 'Wind Speed', 'Wind Direction', 'Wind Gusts',\n",
    "    'Soil Temperature', 'Sunshine Duration', 'UV Index', 'Direct Radiation'\n",
    "]\n",
    "TARGET_VARIABLE = 'Konsumsi Energi'\n",
    "# MINIMUM_ROWS = 3000 # Batas minimum data untuk melatih model\n",
    "MINIMUM_ROWS = 500 # Batas minimum data untuk melatih model (diubah untuk pengujian)\n",
    "\n",
    "print(f\"📁 Folder sumber data diatur ke: '{SOURCE_DATA_DIR}'\")\n",
    "print(f\"📁 Folder hasil akan disimpan di: '{RESULTS_DIR}'\")\n",
    "print(f\"📊 Batas minimum data untuk pelatihan: {MINIMUM_ROWS} baris\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 3. Persiapan Folder dan Unggah Data\n",
    "# ==============================================================================\n",
    "# PENTING: Sebelum menjalankan sel-sel berikutnya, unggah data Anda.\n",
    "#\n",
    "# 1. Di panel file sebelah kiri Google Colab, Anda akan melihat folder 'sumber_data'.\n",
    "# 2. Klik kanan pada folder 'sumber_data' tersebut dan pilih 'Upload'.\n",
    "# 3. Unggah folder 'witel' dan 'opmc' Anda yang berisi semua data CSV\n",
    "#    ke dalam folder 'sumber_data'.\n",
    "#\n",
    "# Setelah selesai, Anda bisa melanjutkan menjalankan sel-sel berikutnya.\n",
    "\n",
    "print(\"✅ Sel ini siap.\")\n",
    "print(f\"Pastikan Anda telah mengunggah data Anda ke dalam folder '{SOURCE_DATA_DIR}'.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 4. Definisi Fungsi-Fungsi Pembantu\n",
    "# ==============================================================================\n",
    "# Sel ini berisi fungsi-fungsi utama untuk melatih model dan membuat visualisasi.\n",
    "# Jalankan sel ini untuk mendefinisikan fungsi agar bisa digunakan nanti.\n",
    "\n",
    "def train_and_evaluate_models(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melatih semua model (RF, GB, LSTM) dan mengembalikan\n",
    "    prediksi serta metrik kinerjanya.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # --- Model 1: Random Forest Regressor ---\n",
    "    print(\"   - Melatih Random Forest...\")\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    results['RandomForest'] = {'model': rf_model, 'predictions': y_pred_rf, 'mae': mean_absolute_error(y_test, y_pred_rf), 'rmse': np.sqrt(mean_squared_error(y_test, y_pred_rf)), 'r2': r2_score(y_test, y_pred_rf)}\n",
    "\n",
    "    # --- Model 2: Gradient Boosting Regressor ---\n",
    "    print(\"   - Melatih Gradient Boosting...\")\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    y_pred_gb = gb_model.predict(X_test)\n",
    "    results['GradientBoosting'] = {'model': gb_model, 'predictions': y_pred_gb, 'mae': mean_absolute_error(y_test, y_pred_gb), 'rmse': np.sqrt(mean_squared_error(y_test, y_pred_gb)), 'r2': r2_score(y_test, y_pred_gb)}\n",
    "\n",
    "    # --- Model 3: LSTM ---\n",
    "    print(\"   - Melatih LSTM...\")\n",
    "    scaler_X = MinMaxScaler(feature_range=(0, 1)); scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train); y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "    X_val_scaled = scaler_X.transform(X_val); y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1))\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "    X_val_lstm = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
    "    X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "    lstm_model = Sequential([LSTM(50, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])), Dense(1)])\n",
    "    lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    lstm_model.fit(X_train_lstm, y_train_scaled, epochs=50, batch_size=32, validation_data=(X_val_lstm, y_val_scaled), verbose=0, shuffle=False)\n",
    "    y_pred_lstm_scaled = lstm_model.predict(X_test_lstm)\n",
    "    y_pred_lstm = scaler_y.inverse_transform(y_pred_lstm_scaled)\n",
    "    results['LSTM'] = {'model': lstm_model, 'predictions': y_pred_lstm.flatten(), 'mae': mean_absolute_error(y_test, y_pred_lstm), 'rmse': np.sqrt(mean_squared_error(y_test, y_pred_lstm)), 'r2': r2_score(y_test, y_pred_lstm)}\n",
    "    return results\n",
    "\n",
    "def create_prediction_plots(y_test, predictions, plot_suffix, output_dir):\n",
    "    \"\"\"Membuat dan menyimpan scatter plot dan line graph untuk prediksi.\"\"\"\n",
    "    # --- Konversi ke kWh untuk semua plot ---\n",
    "    y_test_kwh = y_test / 1000\n",
    "    predictions_kwh = {name: pred / 1000 for name, pred in predictions.items()}\n",
    "\n",
    "    # --- Scatter Plot (Semua Data Test) ---\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    colors = ['green', 'red', 'orange']\n",
    "    for i, (model_name, pred_kwh) in enumerate(predictions_kwh.items()):\n",
    "        mae_kwh = mean_absolute_error(y_test_kwh, pred_kwh)\n",
    "        rmse_kwh = np.sqrt(mean_squared_error(y_test_kwh, pred_kwh))\n",
    "        r2 = r2_score(y_test_kwh, pred_kwh)\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.scatter(y_test_kwh, pred_kwh, alpha=0.6, edgecolors='k', color=colors[i])\n",
    "        plt.plot([y_test_kwh.min(), y_test_kwh.max()], [y_test_kwh.min(), y_test_kwh.max()], '--r', linewidth=2)\n",
    "        plt.title(f'{model_name}\\nR2: {r2:.2f} | RMSE: {rmse_kwh:.2f} | MAE: {mae_kwh:.2f} kWh')\n",
    "        plt.xlabel('Nilai Aktual (kWh)')\n",
    "        plt.ylabel('Nilai Prediksi (kWh)')\n",
    "        plt.grid(True)\n",
    "    plt.suptitle(f'Scatter Plot (Semua Data Test) - {plot_suffix}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(os.path.join(output_dir, f'scatter_plot_{plot_suffix}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # --- Persiapan DataFrame untuk Plot Zoom ---\n",
    "    plot_df_full = pd.DataFrame({'Aktual (kWh)': y_test_kwh})\n",
    "    for model_name, pred_kwh in predictions_kwh.items():\n",
    "        plot_df_full[model_name] = pred_kwh\n",
    "\n",
    "    # PEMBARUAN: Mengambil 500 data terakhir untuk zoom\n",
    "    plot_df_zoom = plot_df_full.tail(500)\n",
    "\n",
    "    # --- Scatter Plot Zoom (500 Data Terakhir) ---\n",
    "    if not plot_df_zoom.empty:\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        for i, model_name in enumerate(predictions_kwh.keys()):\n",
    "            y_test_zoom = plot_df_zoom['Aktual (kWh)']\n",
    "            pred_zoom = plot_df_zoom[model_name]\n",
    "            mae_kwh = mean_absolute_error(y_test_zoom, pred_zoom)\n",
    "            rmse_kwh = np.sqrt(mean_squared_error(y_test_zoom, pred_zoom))\n",
    "            r2 = r2_score(y_test_zoom, pred_zoom)\n",
    "            plt.subplot(1, 3, i + 1)\n",
    "            plt.scatter(y_test_zoom, pred_zoom, alpha=0.6, edgecolors='k', color=colors[i])\n",
    "            plt.plot([y_test_zoom.min(), y_test_zoom.max()], [y_test_zoom.min(), y_test_zoom.max()], '--r', linewidth=2)\n",
    "            plt.title(f'{model_name}\\nR2: {r2:.2f} | RMSE: {rmse_kwh:.2f} | MAE: {mae_kwh:.2f} kWh')\n",
    "            plt.xlabel('Nilai Aktual (kWh)')\n",
    "            plt.ylabel('Nilai Prediksi (kWh)')\n",
    "            plt.grid(True)\n",
    "        plt.suptitle(f'Scatter Plot Zoom (500 Data Terakhir) - {plot_suffix}', fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.savefig(os.path.join(output_dir, f'scatter_plot_zoom_{plot_suffix}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    # --- Grafik Waktu (Titik Acak) ---\n",
    "    plot_df_full.sort_index(inplace=True)\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(plot_df_full.index, plot_df_full['Aktual (kWh)'], label='Nilai Aktual', color='blue', marker='o', linestyle='None', markersize=5, alpha=0.8)\n",
    "    plt.plot(plot_df_full.index, plot_df_full['RandomForest'], label='Prediksi RF', color='green', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "    plt.plot(plot_df_full.index, plot_df_full['GradientBoosting'], label='Prediksi GB', color='red', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "    plt.plot(plot_df_full.index, plot_df_full['LSTM'], label='Prediksi LSTM', color='orange', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "    plt.title(f'Grafik Waktu: Prediksi vs Aktual - {plot_suffix}\\n(Menampilkan titik data dari Test Set yang acak)', fontsize=16)\n",
    "    plt.xlabel('Waktu'); plt.ylabel('Konsumsi Energi (kWh)')\n",
    "    plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'time_series_plot_{plot_suffix}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # --- Grafik Waktu Zoom (500 Data Terakhir) ---\n",
    "    if not plot_df_zoom.empty:\n",
    "        plt.figure(figsize=(20, 8))\n",
    "        plt.plot(plot_df_zoom.index, plot_df_zoom['Aktual (kWh)'], label='Nilai Aktual', color='blue', marker='o', linestyle='None', markersize=5, alpha=0.8)\n",
    "        plt.plot(plot_df_zoom.index, plot_df_zoom['RandomForest'], label='Prediksi RF', color='green', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "        plt.plot(plot_df_zoom.index, plot_df_zoom['GradientBoosting'], label='Prediksi GB', color='red', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "        plt.plot(plot_df_zoom.index, plot_df_zoom['LSTM'], label='Prediksi LSTM', color='orange', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "        plt.title(f'Grafik Waktu Zoom (500 Data Terakhir) - {plot_suffix}', fontsize=16)\n",
    "        plt.xlabel('Waktu'); plt.ylabel('Konsumsi Energi (kWh)')\n",
    "        plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'time_series_plot_zoom_{plot_suffix}.png'))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def create_combined_heatmap(performance_data, title_suffix, output_dir):\n",
    "    \"\"\"Membuat dan menyimpan heatmap gabungan dari data kinerja model.\"\"\"\n",
    "    if not performance_data:\n",
    "        print(f\"Tidak ada data kinerja untuk membuat heatmap.\")\n",
    "        return\n",
    "    df = pd.DataFrame(performance_data)\n",
    "\n",
    "    df['Label Perangkat'] = df['Gedung'] + ' - ' + df['Perangkat']\n",
    "    try:\n",
    "        df.sort_values(by=['Gedung', 'Label Perangkat'], inplace=True)\n",
    "        mae_pivot = df.pivot_table(index='Model', columns='Label Perangkat', values='MAE')\n",
    "        rmse_pivot = df.pivot_table(index='Model', columns='Label Perangkat', values='RMSE')\n",
    "        r2_pivot = df.pivot_table(index='Model', columns='Label Perangkat', values='R2')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat membuat pivot table untuk {title_suffix}: {e}\\nData: {df}\")\n",
    "        return\n",
    "\n",
    "    num_devices = len(df['Label Perangkat'].unique())\n",
    "    fig_width = max(18, num_devices * 1.5)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(fig_width, 21))\n",
    "    fig.suptitle(f'Heatmap Kinerja Model - {title_suffix}', fontsize=20)\n",
    "\n",
    "    # Heatmap R2\n",
    "    sns.heatmap(r2_pivot, annot=True, fmt=\".2f\", cmap=\"viridis\", ax=axes[0], linewidths=.5)\n",
    "    axes[0].set_title('R2 Score - Lebih Tinggi Lebih Baik', fontsize=16)\n",
    "    axes[0].set_xlabel(''); axes[0].set_ylabel('Model', fontsize=12)\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Heatmap RMSE\n",
    "    sns.heatmap(rmse_pivot, annot=True, fmt=\".2f\", cmap=\"viridis_r\", ax=axes[1], linewidths=.5)\n",
    "    axes[1].set_title('RMSE (kWh) - Lebih Rendah Lebih Baik', fontsize=16)\n",
    "    axes[1].set_xlabel(''); axes[1].set_ylabel('Model', fontsize=12)\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Heatmap MAE\n",
    "    sns.heatmap(mae_pivot, annot=True, fmt=\".2f\", cmap=\"viridis_r\", ax=axes[2], linewidths=.5)\n",
    "    axes[2].set_title('MAE (kWh) - Lebih Rendah Lebih Baik', fontsize=16)\n",
    "    axes[2].set_xlabel('Gedung - Perangkat / Lokasi', fontsize=12)\n",
    "    axes[2].set_ylabel('Model', fontsize=12)\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    heatmap_path = os.path.join(output_dir, f'heatmap_{title_suffix}.png')\n",
    "    plt.savefig(heatmap_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"\\nHeatmap gabungan disimpan di: {heatmap_path}\")\n",
    "\n",
    "print(\"✅ Fungsi-fungsi pembantu berhasil didefinisikan.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 5. Memuat, Membersihkan, dan Menggabungkan Data\n",
    "# ==============================================================================\n",
    "# Sel ini akan memuat semua data, membersihkannya, dan menggabungkannya\n",
    "# berdasarkan jenis perangkat di setiap gedung.\n",
    "\n",
    "grouped_data = {}\n",
    "consumption_ranking = []\n",
    "\n",
    "print(\"Memulai proses pemuatan dan penggabungan data...\")\n",
    "for root, dirs, files in os.walk(SOURCE_DATA_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, index_col='id_time', parse_dates=True)\n",
    "\n",
    "                if TARGET_VARIABLE not in df.columns or df[TARGET_VARIABLE].isnull().all():\n",
    "                    continue\n",
    "\n",
    "                df_cleaned = df[[TARGET_VARIABLE]].dropna()\n",
    "                df_cleaned = df_cleaned[df_cleaned[TARGET_VARIABLE] > 0]\n",
    "\n",
    "                if not df_cleaned.empty:\n",
    "                    path_parts = os.path.relpath(root, SOURCE_DATA_DIR).split(os.sep)\n",
    "                    building = path_parts[0]\n",
    "                    device_label = \"_\".join(path_parts[1:])\n",
    "                    avg_consumption = df_cleaned[TARGET_VARIABLE].mean()\n",
    "                    consumption_ranking.append({\n",
    "                        'label': f\"{building} - {device_label}\",\n",
    "                        'avg_kwh': avg_consumption / 1000\n",
    "                    })\n",
    "\n",
    "                path_parts = os.path.relpath(root, SOURCE_DATA_DIR).split(os.sep)\n",
    "                building = path_parts[0]\n",
    "                device_type = path_parts[-1].split('_')[0].lower()\n",
    "\n",
    "                group_key = f\"{building}_{device_type}\"\n",
    "\n",
    "                if group_key not in grouped_data:\n",
    "                    grouped_data[group_key] = []\n",
    "\n",
    "                grouped_data[group_key].append(df)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   - Gagal memproses {file_path}: {e}\")\n",
    "\n",
    "for key, df_list in grouped_data.items():\n",
    "    grouped_data[key] = pd.concat(df_list, ignore_index=False)\n",
    "    print(f\"✅ Data untuk '{key}' berhasil digabungkan, total {len(grouped_data[key])} baris.\")\n",
    "\n",
    "print(\"\\n--- Peringkat Konsumsi Energi Rata-Rata Terbesar ---\")\n",
    "consumption_ranking.sort(key=lambda x: x['avg_kwh'], reverse=True)\n",
    "for i, item in enumerate(consumption_ranking):\n",
    "    print(f\"{i+1}. {item['label']}: {item['avg_kwh']:.2f} kWh\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 6. Proses Utama: Melatih Model per Jenis Perangkat\n",
    "# ==============================================================================\n",
    "# Sel ini akan melakukan loop melalui data yang sudah digabungkan,\n",
    "# melatih model, dan menyimpan hasilnya.\n",
    "\n",
    "best_model_counter = Counter()\n",
    "all_model_stats = []\n",
    "total_models_trained = 0\n",
    "building_predictions_tracker = {}\n",
    "\n",
    "\n",
    "for group_name, df_group in grouped_data.items():\n",
    "    print(f\"\\n{'='*50}\\nMemproses Grup: {group_name.upper()}\\n{'='*50}\")\n",
    "\n",
    "    existing_cols = [col for col in RELEVANT_COLUMNS if col in df_group.columns]\n",
    "    df_processed = df_group.reindex(columns=existing_cols).copy()\n",
    "    df_processed.dropna(subset=[TARGET_VARIABLE], inplace=True)\n",
    "\n",
    "    # --- Penanganan Fitur ---\n",
    "    # 1. Tambahkan fitur lag 1 jam, yang akan selalu digunakan\n",
    "    df_processed['Konsumsi_Energi_Lag_1'] = df_processed[TARGET_VARIABLE].shift(1)\n",
    "\n",
    "    # 2. Ubah 'Wind Direction' menjadi komponen sinus dan kosinus\n",
    "    if 'Wind Direction' in df_processed.columns:\n",
    "        df_processed['Wind_Direction_sin'] = np.sin(np.deg2rad(df_processed['Wind Direction']))\n",
    "        df_processed['Wind_Direction_cos'] = np.cos(np.deg2rad(df_processed['Wind Direction']))\n",
    "        df_processed.drop('Wind Direction', axis=1, inplace=True)\n",
    "\n",
    "    # 3. Terapkan one-hot encoding pada 'Weather Code'\n",
    "    if 'Weather Code' in df_processed.columns:\n",
    "        df_processed = pd.get_dummies(df_processed, columns=['Weather Code'], prefix='WeatherCode')\n",
    "\n",
    "    # Hapus baris dengan NaN yang mungkin muncul dari fitur lag\n",
    "    df_processed.dropna(inplace=True)\n",
    "    df_final = df_processed[df_processed[TARGET_VARIABLE] > 0].copy()\n",
    "\n",
    "    if len(df_final) < MINIMUM_ROWS:\n",
    "        print(f\"   - ⚠️ PERINGATAN: Data tidak cukup ({len(df_final)} baris). Melewati pelatihan untuk grup ini.\")\n",
    "        continue\n",
    "\n",
    "    # --- PEMBARUAN: Logika Seleksi Fitur Baru ---\n",
    "    print(\"\\n   --- Memulai Seleksi Fitur ---\")\n",
    "    correlation_matrix = df_final.corr(method='spearman')\n",
    "\n",
    "    output_dir = os.path.join(RESULTS_DIR, *group_name.split('_'))\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Simpan heatmap korelasi\n",
    "    show_annotations = len(correlation_matrix.columns) < 40\n",
    "    plt.figure(figsize=(22, 18))\n",
    "    sns.heatmap(correlation_matrix, annot=show_annotations, cmap='coolwarm', fmt=\".2f\")\n",
    "    plt.title(f'Correlation Matrix (Spearman) - {group_name}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'correlation_matrix_{group_name}.png'))\n",
    "    plt.close()\n",
    "    print(f\"   - Heatmap korelasi disimpan di: {output_dir}\")\n",
    "\n",
    "    # 1. TAHAP 1: Analisis Multikolinearitas (diluar fitur target dan lag)\n",
    "    potential_features = [col for col in df_final.columns if col not in [TARGET_VARIABLE, 'Konsumsi_Energi_Lag_1']]\n",
    "    feature_corr_matrix = df_final[potential_features].corr().abs()\n",
    "    \n",
    "    upper_tri = feature_corr_matrix.where(np.triu(np.ones(feature_corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] >= 0.8)]\n",
    "    \n",
    "    independent_features = [f for f in potential_features if f not in to_drop]\n",
    "    print(f\"   - Tahap 1: Ditemukan {len(to_drop)} fitur dengan multikolinearitas (dihapus): {to_drop}\")\n",
    "    print(f\"   - Tahap 1: Terdapat {len(independent_features)} fitur independen yang tersisa.\")\n",
    "\n",
    "    # 2. TAHAP 2: Analisis Korelasi dengan Target dari Fitur Independen (THRESHOLD DINAMIS)\n",
    "    highly_correlated_features = []\n",
    "    if independent_features:\n",
    "        target_correlations = correlation_matrix.loc[independent_features, TARGET_VARIABLE]\n",
    "        # Coba threshold 0.4 terlebih dahulu\n",
    "        highly_correlated_features = target_correlations[\n",
    "            (target_correlations >= 0.4) | (target_correlations <= -0.4)\n",
    "        ].index.tolist()\n",
    "        \n",
    "        # Jika tidak ada, turunkan threshold ke 0.3\n",
    "        if not highly_correlated_features:\n",
    "            print(f\"   - Tahap 2: Tidak ditemukan fitur dengan korelasi |r| >= 0.4. Menurunkan threshold ke 0.3...\")\n",
    "            highly_correlated_features = target_correlations[\n",
    "                (target_correlations >= 0.3) | (target_correlations <= -0.3)\n",
    "            ].index.tolist()\n",
    "            print(f\"   - Tahap 2 (Revisi): Ditemukan {len(highly_correlated_features)} fitur dengan korelasi |r| >= 0.3: {highly_correlated_features}\")\n",
    "        else:\n",
    "            print(f\"   - Tahap 2: Ditemukan {len(highly_correlated_features)} fitur independen yang berkorelasi kuat dengan target (|r| >= 0.4): {highly_correlated_features}\")\n",
    "\n",
    "    # 3. TAHAP 3: Fitur Terpilih Final\n",
    "    features_for_model = ['Konsumsi_Energi_Lag_1'] + highly_correlated_features\n",
    "    features_for_model = list(dict.fromkeys(features_for_model)) # Pastikan tidak ada duplikat\n",
    "\n",
    "    print(f\"   - Tahap 3: Fitur final untuk model: {features_for_model}\\n\")\n",
    "    \n",
    "    # Simpan fitur terpilih ke CSV\n",
    "    pd.DataFrame({'fitur_terpilih': features_for_model}).to_csv(os.path.join(output_dir, f'fitur_terpilih_{group_name}.csv'), index=False)\n",
    "\n",
    "    # PEMBARUAN: Lanjutkan pelatihan meskipun hanya ada 1 fitur\n",
    "    if not features_for_model:\n",
    "        print(\"   - Tidak ada fitur sama sekali untuk model. Melewati grup ini.\"); continue\n",
    "\n",
    "    X = df_final[features_for_model]; y = df_final[TARGET_VARIABLE]\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    if len(X_train) == 0 or len(X_test) == 0: continue\n",
    "\n",
    "    print(f\"   - Ukuran Data: Latih={len(X_train)}, Validasi={len(X_val)}, Uji={len(X_test)} (Acak)\")\n",
    "    model_evaluations = train_and_evaluate_models(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "    device_predictions = {name: data['predictions'] for name, data in model_evaluations.items()}\n",
    "    create_prediction_plots(y_test, device_predictions, group_name, output_dir)\n",
    "    print(f\"   - Plot prediksi untuk grup '{group_name}' disimpan.\")\n",
    "\n",
    "    building_name, device_type = group_name.split('_', 1)\n",
    "    if building_name not in building_predictions_tracker:\n",
    "        building_predictions_tracker[building_name] = {'y_true': [], 'preds': {'RandomForest': [], 'GradientBoosting': [], 'LSTM': []}}\n",
    "\n",
    "    building_predictions_tracker[building_name]['y_true'].append(y_test)\n",
    "    for model_name, preds in device_predictions.items():\n",
    "        building_predictions_tracker[building_name]['preds'][model_name].append(preds)\n",
    "\n",
    "    best_model_name, best_model_mae = '', float('inf')\n",
    "    for model_name, eval_data in model_evaluations.items():\n",
    "        if eval_data['mae'] < best_model_mae:\n",
    "            best_model_mae = eval_data['mae']\n",
    "            best_model_name = model_name\n",
    "\n",
    "        all_model_stats.append({\n",
    "            'Gedung': building_name,\n",
    "            'Perangkat': device_type,\n",
    "            'Model': model_name,\n",
    "            'MAE': eval_data['mae'] / 1000,\n",
    "            'RMSE': eval_data['rmse'] / 1000,\n",
    "            'R2': eval_data['r2']\n",
    "        })\n",
    "\n",
    "    best_model_counter[best_model_name] += 1\n",
    "    total_models_trained += 1\n",
    "    print(f\"   ==> Model terbaik untuk grup ini adalah {best_model_name} (berdasarkan MAE).\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 7. Ringkasan dan Analisis Final\n",
    "# ==============================================================================\n",
    "# Sel ini akan menampilkan ringkasan model terbaik dan statistik evaluasi.\n",
    "\n",
    "if total_models_trained > 0:\n",
    "    stats_df = pd.DataFrame(all_model_stats)\n",
    "    stats_df.to_csv(os.path.join(RESULTS_DIR, 'laporan_kinerja_semua_model.csv'), index=False)\n",
    "    print(f\"\\n✅ Laporan kinerja lengkap disimpan di: {os.path.join(RESULTS_DIR, 'laporan_kinerja_semua_model.csv')}\")\n",
    "\n",
    "\n",
    "    # --- 1. Ringkasan Model Terbaik ---\n",
    "    print(f\"\\n{'='*50}\\nRingkasan Model Terbaik (dari {total_models_trained} grup perangkat)\\n{'='*50}\")\n",
    "    sorted_models = best_model_counter.most_common()\n",
    "    for model, count in sorted_models:\n",
    "        percentage = (count / total_models_trained) * 100\n",
    "        print(f\"🏆 {model}: Model terbaik sebanyak {count}/{total_models_trained} kali ({percentage:.1f}%)\")\n",
    "\n",
    "    # --- 2. Statistik Evaluasi Keseluruhan ---\n",
    "    print(f\"\\n{'='*50}\\nStatistik Evaluasi Keseluruhan (Rata-rata dari semua model)\\n{'='*50}\")\n",
    "    overall_avg = stats_df[['R2', 'RMSE', 'MAE']].mean()\n",
    "    print(f\"Rata-rata R2 Score : {overall_avg['R2']:.2f}\")\n",
    "    print(f\"Rata-rata RMSE     : {overall_avg['RMSE']:.2f} kWh\")\n",
    "    print(f\"Rata-rata MAE      : {overall_avg['MAE']:.2f} kWh\")\n",
    "\n",
    "    # --- 3. Rata-Rata Metrik per Model ---\n",
    "    print(f\"\\n{'='*50}\\nRata-Rata Metrik per Model\\n{'='*50}\")\n",
    "    per_model_avg = stats_df.groupby('Model')[['R2', 'RMSE', 'MAE']].mean()\n",
    "    print(per_model_avg.round(2))\n",
    "\n",
    "    # --- 4. Detail Metrik Evaluasi per Grup Perangkat ---\n",
    "    print(f\"\\n{'='*50}\\nDetail Metrik Evaluasi per Grup Perangkat\\n{'='*50}\")\n",
    "    for group, group_df in stats_df.groupby(['Gedung', 'Perangkat']):\n",
    "        print(f\"\\n--- Grup: {group[0].upper()} - {group[1].upper()} ---\")\n",
    "        best_model_in_group = group_df.loc[group_df['MAE'].idxmin()]\n",
    "        for index, row in group_df.iterrows():\n",
    "            is_best = \"🏆\" if row['Model'] == best_model_in_group['Model'] else \"\"\n",
    "            print(f\"  - Model: {row['Model']:<17} | R2: {row['R2']:.2f} | RMSE: {row['RMSE']:.2f} kWh | MAE: {row['MAE']:.2f} kWh {is_best}\")\n",
    "\n",
    "    # --- 5. Membuat Plot Gabungan per Gedung ---\n",
    "    print(f\"\\n{'='*50}\\nMembuat Plot Gabungan per Gedung\\n{'='*50}\")\n",
    "    for building_name, data in building_predictions_tracker.items():\n",
    "        y_true_combined = pd.concat(data['y_true'])\n",
    "        preds_combined = {model: np.concatenate(preds) for model, preds in data['preds'].items()}\n",
    "\n",
    "        building_output_dir = os.path.join(RESULTS_DIR, building_name)\n",
    "        os.makedirs(building_output_dir, exist_ok=True)\n",
    "\n",
    "        create_prediction_plots(y_true_combined, preds_combined, f\"Gabungan_{building_name.upper()}\", building_output_dir)\n",
    "        print(f\"✅ Plot prediksi gabungan untuk gedung '{building_name}' disimpan di: {building_output_dir}\")\n",
    "        \n",
    "    # --- 6. Membuat Heatmap Kinerja Gabungan ---\n",
    "    print(f\"\\n{'='*50}\\nMembuat Heatmap Kinerja Gabungan\\n{'='*50}\")\n",
    "    create_combined_heatmap(all_model_stats, \"Kinerja_Gabungan_Semua_Gedung\", RESULTS_DIR)\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"\\nTidak ada model yang dilatih, ringkasan tidak dapat dibuat.\")\n",
    "\n",
    "print(f\"\\n\\n🏁 Proses Selesai. Semua hasil telah disimpan di folder '{RESULTS_DIR}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1fbfb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Library berhasil diimpor.\n",
      "📁 Folder sumber data diatur ke: 'sumber_data'\n",
      "📁 Folder hasil akan disimpan di: 'hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur'\n",
      "📊 Batas minimum data untuk pelatihan: 500 baris\n",
      "✅ Sel ini siap.\n",
      "Pastikan Anda telah mengunggah data Anda ke dalam folder 'sumber_data'.\n",
      "✅ Fungsi-fungsi pembantu berhasil didefinisikan.\n",
      "Memulai proses pemuatan dan penggabungan data...\n",
      "✅ Data untuk 'opmc_sdp' berhasil digabungkan, total 52674 baris.\n",
      "✅ Data untuk 'opmc_ahu' berhasil digabungkan, total 43893 baris.\n",
      "✅ Data untuk 'opmc_lift' berhasil digabungkan, total 1121 baris.\n",
      "✅ Data untuk 'witel_sdp' berhasil digabungkan, total 70259 baris.\n",
      "✅ Data untuk 'witel_ahu' berhasil digabungkan, total 70039 baris.\n",
      "✅ Data untuk 'witel_lift' berhasil digabungkan, total 8777 baris.\n",
      "✅ Data untuk 'witel_chiller' berhasil digabungkan, total 1121 baris.\n",
      "\n",
      "--- Peringkat Konsumsi Energi Rata-Rata Terbesar ---\n",
      "1. opmc - LIFT: 326.63 kWh\n",
      "2. witel - CHILLER: 326.63 kWh\n",
      "3. witel - Lantai7_SDP: 57.95 kWh\n",
      "4. witel - Lantai7_AHU: 35.70 kWh\n",
      "5. witel - Lantai6_SDP: 35.65 kWh\n",
      "6. witel - Lantai8_AHU: 35.06 kWh\n",
      "7. witel - Lantai6_AHU: 31.47 kWh\n",
      "8. opmc - Lantai5_AHU: 29.07 kWh\n",
      "9. witel - Lantai1_SDP: 24.09 kWh\n",
      "10. opmc - Lantai6_SDP: 23.63 kWh\n",
      "11. opmc - Lantai3_AHU: 22.52 kWh\n",
      "12. witel - LIFT: 20.16 kWh\n",
      "13. opmc - Lantai5_SDP: 18.59 kWh\n",
      "14. witel - Lantai1_AHU: 17.54 kWh\n",
      "15. witel - Lantai3_SDP: 16.32 kWh\n",
      "16. opmc - Lantai1_SDP: 15.65 kWh\n",
      "17. opmc - Lantai4_AHU: 13.23 kWh\n",
      "18. witel - Lantai2_SDP: 13.12 kWh\n",
      "19. witel - Lantai5_SDP: 12.35 kWh\n",
      "20. witel - Lantai5_AHU: 12.31 kWh\n",
      "21. opmc - Lantai2_SDP: 7.98 kWh\n",
      "22. opmc - Lantai3_SDP: 5.32 kWh\n",
      "23. witel - Lantai3_AHU: 5.20 kWh\n",
      "24. witel - Lantai2_AHU: 4.98 kWh\n",
      "25. witel - Lantai4_AHU: 4.79 kWh\n",
      "26. opmc - Lantai2_AHU: 3.89 kWh\n",
      "27. witel - Lantai8_SDP: 3.44 kWh\n",
      "28. opmc - Lantai4_SDP: 2.59 kWh\n",
      "29. witel - Lantai4_SDP: 2.59 kWh\n",
      "\n",
      "📅 Mengambil data hari libur nasional Indonesia untuk tahun: [2024]\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: OPMC_SDP\n",
      "==================================================\n",
      "   - Menambahkan fitur 'is_weekend' dan 'isHoliday'.\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur/opmc/sdp\n",
      "   - Tahap 1: Ditemukan 9 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'Sunshine Duration', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 11 fitur independen yang tersisa.\n",
      "   - Tahap 2: Tidak ditemukan fitur dengan korelasi |r| >= 0.4. Menurunkan threshold ke 0.3...\n",
      "   - Tahap 2 (Revisi): Ditemukan 1 fitur dengan korelasi |r| >= 0.3: ['Temperature']\n",
      "   - Fitur 'is_weekend' dilewati (korelasi: 0.22 < 0.3).\n",
      "   - Fitur 'isHoliday' dilewati (korelasi: 0.02 < 0.3).\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1', 'Temperature']\n",
      "\n",
      "   - Ukuran Data: Latih=26748, Validasi=5732, Uji=5732 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "   - Plot prediksi untuk grup 'opmc_sdp' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah GradientBoosting (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: OPMC_AHU\n",
      "==================================================\n",
      "   - Menambahkan fitur 'is_weekend' dan 'isHoliday'.\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur/opmc/ahu\n",
      "   - Tahap 1: Ditemukan 9 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'Sunshine Duration', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 11 fitur independen yang tersisa.\n",
      "   - Tahap 2: Ditemukan 1 fitur independen yang berkorelasi kuat dengan target (|r| >= 0.4): ['Temperature']\n",
      "   - Fitur 'is_weekend' dilewati (korelasi: 0.30 < 0.3).\n",
      "   - Fitur 'isHoliday' dilewati (korelasi: 0.03 < 0.3).\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1', 'Temperature']\n",
      "\n",
      "   - Ukuran Data: Latih=11334, Validasi=2429, Uji=2429 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "   - Plot prediksi untuk grup 'opmc_ahu' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah GradientBoosting (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: OPMC_LIFT\n",
      "==================================================\n",
      "   - Menambahkan fitur 'is_weekend' dan 'isHoliday'.\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur/opmc/lift\n",
      "   - Tahap 1: Ditemukan 8 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 12 fitur independen yang tersisa.\n",
      "   - Tahap 2: Tidak ditemukan fitur dengan korelasi |r| >= 0.4. Menurunkan threshold ke 0.3...\n",
      "   - Tahap 2 (Revisi): Ditemukan 3 fitur dengan korelasi |r| >= 0.3: ['Temperature', 'Wind Speed', 'Sunshine Duration']\n",
      "   - Fitur 'is_weekend' dilewati (korelasi: 0.23 < 0.3).\n",
      "   - Fitur 'isHoliday' dilewati (korelasi: 0.03 < 0.3).\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1', 'Temperature', 'Wind Speed', 'Sunshine Duration']\n",
      "\n",
      "   - Ukuran Data: Latih=706, Validasi=151, Uji=152 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "   - Plot prediksi untuk grup 'opmc_lift' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah RandomForest (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: WITEL_SDP\n",
      "==================================================\n",
      "   - Menambahkan fitur 'is_weekend' dan 'isHoliday'.\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur/witel/sdp\n",
      "   - Tahap 1: Ditemukan 9 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'Sunshine Duration', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 11 fitur independen yang tersisa.\n",
      "   - Tahap 2: Tidak ditemukan fitur dengan korelasi |r| >= 0.4. Menurunkan threshold ke 0.3...\n",
      "   - Tahap 2 (Revisi): Ditemukan 0 fitur dengan korelasi |r| >= 0.3: []\n",
      "   - Fitur 'is_weekend' dilewati (korelasi: 0.23 < 0.3).\n",
      "   - Fitur 'isHoliday' dilewati (korelasi: 0.02 < 0.3).\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1']\n",
      "\n",
      "   - Ukuran Data: Latih=34964, Validasi=7492, Uji=7493 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "   - Plot prediksi untuk grup 'witel_sdp' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah LSTM (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: WITEL_AHU\n",
      "==================================================\n",
      "   - Menambahkan fitur 'is_weekend' dan 'isHoliday'.\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur/witel/ahu\n",
      "   - Tahap 1: Ditemukan 8 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 12 fitur independen yang tersisa.\n",
      "   - Tahap 2: Ditemukan 2 fitur independen yang berkorelasi kuat dengan target (|r| >= 0.4): ['Temperature', 'Sunshine Duration']\n",
      "   - Fitur 'is_weekend' ditambahkan (korelasi: 0.37).\n",
      "   - Fitur 'isHoliday' dilewati (korelasi: 0.03 < 0.3).\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1', 'Temperature', 'Sunshine Duration', 'is_weekend']\n",
      "\n",
      "   - Ukuran Data: Latih=24814, Validasi=5317, Uji=5318 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "   - Plot prediksi untuk grup 'witel_ahu' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah GradientBoosting (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: WITEL_LIFT\n",
      "==================================================\n",
      "   - Menambahkan fitur 'is_weekend' dan 'isHoliday'.\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur/witel/lift\n",
      "   - Tahap 1: Ditemukan 9 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'Sunshine Duration', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 11 fitur independen yang tersisa.\n",
      "   - Tahap 2: Ditemukan 1 fitur independen yang berkorelasi kuat dengan target (|r| >= 0.4): ['Temperature']\n",
      "   - Fitur 'is_weekend' dilewati (korelasi: 0.26 < 0.3).\n",
      "   - Fitur 'isHoliday' dilewati (korelasi: 0.02 < 0.3).\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1', 'Temperature']\n",
      "\n",
      "   - Ukuran Data: Latih=4184, Validasi=897, Uji=897 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "   - Plot prediksi untuk grup 'witel_lift' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah GradientBoosting (berdasarkan MAE).\n",
      "\n",
      "==================================================\n",
      "Memproses Grup: WITEL_CHILLER\n",
      "==================================================\n",
      "   - Menambahkan fitur 'is_weekend' dan 'isHoliday'.\n",
      "\n",
      "   --- Memulai Seleksi Fitur ---\n",
      "   - Heatmap korelasi disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur/witel/chiller\n",
      "   - Tahap 1: Ditemukan 8 fitur dengan multikolinearitas (dihapus): ['Relative Humidity', 'Precipitation', 'Surface Pressure', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'UV Index', 'Direct Radiation']\n",
      "   - Tahap 1: Terdapat 12 fitur independen yang tersisa.\n",
      "   - Tahap 2: Tidak ditemukan fitur dengan korelasi |r| >= 0.4. Menurunkan threshold ke 0.3...\n",
      "   - Tahap 2 (Revisi): Ditemukan 3 fitur dengan korelasi |r| >= 0.3: ['Temperature', 'Wind Speed', 'Sunshine Duration']\n",
      "   - Fitur 'is_weekend' dilewati (korelasi: 0.23 < 0.3).\n",
      "   - Fitur 'isHoliday' dilewati (korelasi: 0.03 < 0.3).\n",
      "   - Tahap 3: Fitur final untuk model: ['Konsumsi_Energi_Lag_1', 'Temperature', 'Wind Speed', 'Sunshine Duration']\n",
      "\n",
      "   - Ukuran Data: Latih=706, Validasi=151, Uji=152 (Acak)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "   - Plot prediksi untuk grup 'witel_chiller' disimpan.\n",
      "   ==> Model terbaik untuk grup ini adalah RandomForest (berdasarkan MAE).\n",
      "\n",
      "✅ Laporan kinerja lengkap disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur/laporan_kinerja_semua_model.csv\n",
      "\n",
      "==================================================\n",
      "Ringkasan Model Terbaik (dari 7 grup perangkat)\n",
      "==================================================\n",
      "🏆 GradientBoosting: Model terbaik sebanyak 4/7 kali (57.1%)\n",
      "🏆 RandomForest: Model terbaik sebanyak 2/7 kali (28.6%)\n",
      "🏆 LSTM: Model terbaik sebanyak 1/7 kali (14.3%)\n",
      "\n",
      "==================================================\n",
      "Statistik Evaluasi Keseluruhan (Rata-rata dari semua model)\n",
      "==================================================\n",
      "Rata-rata R2 Score : 0.72\n",
      "Rata-rata RMSE     : 98.75 kWh\n",
      "Rata-rata MAE      : 40.85 kWh\n",
      "\n",
      "==================================================\n",
      "Rata-Rata Metrik per Model\n",
      "==================================================\n",
      "                    R2    RMSE    MAE\n",
      "Model                                \n",
      "GradientBoosting  0.73  101.21  43.17\n",
      "LSTM              0.72  101.13  40.77\n",
      "RandomForest      0.70   93.91  38.60\n",
      "\n",
      "==================================================\n",
      "Detail Metrik Evaluasi per Grup Perangkat\n",
      "==================================================\n",
      "\n",
      "--- Grup: OPMC - AHU ---\n",
      "  - Model: RandomForest      | R2: 0.68 | RMSE: 11.54 kWh | MAE: 6.78 kWh \n",
      "  - Model: GradientBoosting  | R2: 0.75 | RMSE: 10.27 kWh | MAE: 6.03 kWh 🏆\n",
      "  - Model: LSTM              | R2: 0.74 | RMSE: 10.51 kWh | MAE: 6.30 kWh \n",
      "\n",
      "--- Grup: OPMC - LIFT ---\n",
      "  - Model: RandomForest      | R2: 0.72 | RMSE: 307.36 kWh | MAE: 123.09 kWh 🏆\n",
      "  - Model: GradientBoosting  | R2: 0.67 | RMSE: 334.69 kWh | MAE: 140.10 kWh \n",
      "  - Model: LSTM              | R2: 0.67 | RMSE: 334.27 kWh | MAE: 131.11 kWh \n",
      "\n",
      "--- Grup: OPMC - SDP ---\n",
      "  - Model: RandomForest      | R2: 0.78 | RMSE: 5.78 kWh | MAE: 3.46 kWh \n",
      "  - Model: GradientBoosting  | R2: 0.83 | RMSE: 5.12 kWh | MAE: 2.96 kWh 🏆\n",
      "  - Model: LSTM              | R2: 0.82 | RMSE: 5.22 kWh | MAE: 3.05 kWh \n",
      "\n",
      "--- Grup: WITEL - AHU ---\n",
      "  - Model: RandomForest      | R2: 0.79 | RMSE: 6.69 kWh | MAE: 3.55 kWh \n",
      "  - Model: GradientBoosting  | R2: 0.82 | RMSE: 6.32 kWh | MAE: 3.52 kWh 🏆\n",
      "  - Model: LSTM              | R2: 0.79 | RMSE: 6.73 kWh | MAE: 3.88 kWh \n",
      "\n",
      "--- Grup: WITEL - CHILLER ---\n",
      "  - Model: RandomForest      | R2: 0.72 | RMSE: 307.36 kWh | MAE: 123.09 kWh 🏆\n",
      "  - Model: GradientBoosting  | R2: 0.67 | RMSE: 334.69 kWh | MAE: 140.10 kWh \n",
      "  - Model: LSTM              | R2: 0.67 | RMSE: 333.73 kWh | MAE: 131.58 kWh \n",
      "\n",
      "--- Grup: WITEL - LIFT ---\n",
      "  - Model: RandomForest      | R2: 0.43 | RMSE: 6.28 kWh | MAE: 4.54 kWh \n",
      "  - Model: GradientBoosting  | R2: 0.60 | RMSE: 5.30 kWh | MAE: 3.84 kWh 🏆\n",
      "  - Model: LSTM              | R2: 0.59 | RMSE: 5.38 kWh | MAE: 3.88 kWh \n",
      "\n",
      "--- Grup: WITEL - SDP ---\n",
      "  - Model: RandomForest      | R2: 0.78 | RMSE: 12.34 kWh | MAE: 5.72 kWh \n",
      "  - Model: GradientBoosting  | R2: 0.79 | RMSE: 12.07 kWh | MAE: 5.62 kWh \n",
      "  - Model: LSTM              | R2: 0.79 | RMSE: 12.04 kWh | MAE: 5.61 kWh 🏆\n",
      "\n",
      "==================================================\n",
      "Membuat Plot Gabungan per Gedung\n",
      "==================================================\n",
      "✅ Plot prediksi gabungan untuk gedung 'opmc' disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur/opmc\n",
      "✅ Plot prediksi gabungan untuk gedung 'witel' disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur/witel\n",
      "\n",
      "==================================================\n",
      "Membuat Heatmap Kinerja Gabungan\n",
      "==================================================\n",
      "\n",
      "Heatmap gabungan disimpan di: hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur/heatmap_Kinerja_Gabungan_Semua_Gedung.png\n",
      "\n",
      "\n",
      "🏁 Proses Selesai. Semua hasil telah disimpan di folder 'hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur'.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# @title 1. Instalasi dan Impor Library\n",
    "# ==============================================================================\n",
    "# Jalankan sel ini terlebih dahulu untuk mengimpor semua library yang dibutuhkan.\n",
    "# PEMBARUAN: Menambahkan library 'holidays' untuk data hari libur nasional\n",
    "!pip install holidays -q\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import holidays\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"✅ Library berhasil diimpor.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 2. Konfigurasi Utama\n",
    "# ==============================================================================\n",
    "# Sel ini mendefinisikan variabel-variabel penting seperti lokasi folder\n",
    "# dan daftar kolom yang akan digunakan dalam model.\n",
    "\n",
    "# Tentukan path folder sumber data dan folder untuk menyimpan hasil\n",
    "SOURCE_DATA_DIR = 'sumber_data'\n",
    "# PEMBARUAN: Mengubah nama folder hasil\n",
    "RESULTS_DIR = 'hasil_model_aggregate_pergedung_revisikorelasimatrix_denganharilibur'\n",
    "\n",
    "# Pastikan folder hasil utama dan folder sumber ada\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(SOURCE_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Daftar kolom fitur yang akan digunakan (tanpa 'Apparent Temperature')\n",
    "RELEVANT_COLUMNS = [\n",
    "    'Konsumsi Energi', 'Temperature', 'Showers', 'Cloud Cover', 'Weather Code',\n",
    "    'Relative Humidity', 'Dew Point', 'Precipitation',\n",
    "    'Pressure MSL', 'Surface Pressure', 'Evapotranspiration',\n",
    "    'Vapour Pressure Deficit', 'Wind Speed', 'Wind Direction', 'Wind Gusts',\n",
    "    'Soil Temperature', 'Sunshine Duration', 'UV Index', 'Direct Radiation'\n",
    "]\n",
    "TARGET_VARIABLE = 'Konsumsi Energi'\n",
    "# MINIMUM_ROWS = 3000 # Batas minimum data untuk melatih model\n",
    "MINIMUM_ROWS = 500 # Batas minimum data untuk melatih model (diubah untuk pengujian)\n",
    "\n",
    "print(f\"📁 Folder sumber data diatur ke: '{SOURCE_DATA_DIR}'\")\n",
    "print(f\"📁 Folder hasil akan disimpan di: '{RESULTS_DIR}'\")\n",
    "print(f\"📊 Batas minimum data untuk pelatihan: {MINIMUM_ROWS} baris\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 3. Persiapan Folder dan Unggah Data\n",
    "# ==============================================================================\n",
    "# PENTING: Sebelum menjalankan sel-sel berikutnya, unggah data Anda.\n",
    "#\n",
    "# 1. Di panel file sebelah kiri Google Colab, Anda akan melihat folder 'sumber_data'.\n",
    "# 2. Klik kanan pada folder 'sumber_data' tersebut dan pilih 'Upload'.\n",
    "# 3. Unggah folder 'witel' dan 'opmc' Anda yang berisi semua data CSV\n",
    "#    ke dalam folder 'sumber_data'.\n",
    "#\n",
    "# Setelah selesai, Anda bisa melanjutkan menjalankan sel-sel berikutnya.\n",
    "\n",
    "print(\"✅ Sel ini siap.\")\n",
    "print(f\"Pastikan Anda telah mengunggah data Anda ke dalam folder '{SOURCE_DATA_DIR}'.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 4. Definisi Fungsi-Fungsi Pembantu\n",
    "# ==============================================================================\n",
    "# Sel ini berisi fungsi-fungsi utama untuk melatih model dan membuat visualisasi.\n",
    "# Jalankan sel ini untuk mendefinisikan fungsi agar bisa digunakan nanti.\n",
    "\n",
    "def train_and_evaluate_models(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melatih semua model (RF, GB, LSTM) dan mengembalikan\n",
    "    prediksi serta metrik kinerjanya.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # --- Model 1: Random Forest Regressor ---\n",
    "    print(\"   - Melatih Random Forest...\")\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    results['RandomForest'] = {'model': rf_model, 'predictions': y_pred_rf, 'mae': mean_absolute_error(y_test, y_pred_rf), 'rmse': np.sqrt(mean_squared_error(y_test, y_pred_rf)), 'r2': r2_score(y_test, y_pred_rf)}\n",
    "\n",
    "    # --- Model 2: Gradient Boosting Regressor ---\n",
    "    print(\"   - Melatih Gradient Boosting...\")\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    y_pred_gb = gb_model.predict(X_test)\n",
    "    results['GradientBoosting'] = {'model': gb_model, 'predictions': y_pred_gb, 'mae': mean_absolute_error(y_test, y_pred_gb), 'rmse': np.sqrt(mean_squared_error(y_test, y_pred_gb)), 'r2': r2_score(y_test, y_pred_gb)}\n",
    "\n",
    "    # --- Model 3: LSTM ---\n",
    "    print(\"   - Melatih LSTM...\")\n",
    "    scaler_X = MinMaxScaler(feature_range=(0, 1)); scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train); y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "    X_val_scaled = scaler_X.transform(X_val); y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1))\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "    X_val_lstm = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
    "    X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "    lstm_model = Sequential([LSTM(50, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])), Dense(1)])\n",
    "    lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    lstm_model.fit(X_train_lstm, y_train_scaled, epochs=50, batch_size=32, validation_data=(X_val_lstm, y_val_scaled), verbose=0, shuffle=False)\n",
    "    y_pred_lstm_scaled = lstm_model.predict(X_test_lstm)\n",
    "    y_pred_lstm = scaler_y.inverse_transform(y_pred_lstm_scaled)\n",
    "    results['LSTM'] = {'model': lstm_model, 'predictions': y_pred_lstm.flatten(), 'mae': mean_absolute_error(y_test, y_pred_lstm), 'rmse': np.sqrt(mean_squared_error(y_test, y_pred_lstm)), 'r2': r2_score(y_test, y_pred_lstm)}\n",
    "    return results\n",
    "\n",
    "def create_prediction_plots(y_test, predictions, plot_suffix, output_dir):\n",
    "    \"\"\"Membuat dan menyimpan scatter plot dan line graph untuk prediksi.\"\"\"\n",
    "    # --- Konversi ke kWh untuk semua plot ---\n",
    "    y_test_kwh = y_test / 1000\n",
    "    predictions_kwh = {name: pred / 1000 for name, pred in predictions.items()}\n",
    "\n",
    "    # --- Scatter Plot (Semua Data Test) ---\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    colors = ['green', 'red', 'orange']\n",
    "    for i, (model_name, pred_kwh) in enumerate(predictions_kwh.items()):\n",
    "        mae_kwh = mean_absolute_error(y_test_kwh, pred_kwh)\n",
    "        rmse_kwh = np.sqrt(mean_squared_error(y_test_kwh, pred_kwh))\n",
    "        r2 = r2_score(y_test_kwh, pred_kwh)\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.scatter(y_test_kwh, pred_kwh, alpha=0.6, edgecolors='k', color=colors[i])\n",
    "        plt.plot([y_test_kwh.min(), y_test_kwh.max()], [y_test_kwh.min(), y_test_kwh.max()], '--r', linewidth=2)\n",
    "        plt.title(f'{model_name}\\nR2: {r2:.2f} | RMSE: {rmse_kwh:.2f} | MAE: {mae_kwh:.2f} kWh')\n",
    "        plt.xlabel('Nilai Aktual (kWh)')\n",
    "        plt.ylabel('Nilai Prediksi (kWh)')\n",
    "        plt.grid(True)\n",
    "    plt.suptitle(f'Scatter Plot (Semua Data Test) - {plot_suffix}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(os.path.join(output_dir, f'scatter_plot_{plot_suffix}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # --- Persiapan DataFrame untuk Plot Zoom ---\n",
    "    plot_df_full = pd.DataFrame({'Aktual (kWh)': y_test_kwh})\n",
    "    for model_name, pred_kwh in predictions_kwh.items():\n",
    "        plot_df_full[model_name] = pred_kwh\n",
    "\n",
    "    # PEMBARUAN: Mengambil 500 data terakhir untuk zoom\n",
    "    plot_df_zoom = plot_df_full.tail(500)\n",
    "\n",
    "    # --- Scatter Plot Zoom (500 Data Terakhir) ---\n",
    "    if not plot_df_zoom.empty:\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        for i, model_name in enumerate(predictions_kwh.keys()):\n",
    "            y_test_zoom = plot_df_zoom['Aktual (kWh)']\n",
    "            pred_zoom = plot_df_zoom[model_name]\n",
    "            mae_kwh = mean_absolute_error(y_test_zoom, pred_zoom)\n",
    "            rmse_kwh = np.sqrt(mean_squared_error(y_test_zoom, pred_zoom))\n",
    "            r2 = r2_score(y_test_zoom, pred_zoom)\n",
    "            plt.subplot(1, 3, i + 1)\n",
    "            plt.scatter(y_test_zoom, pred_zoom, alpha=0.6, edgecolors='k', color=colors[i])\n",
    "            plt.plot([y_test_zoom.min(), y_test_zoom.max()], [y_test_zoom.min(), y_test_zoom.max()], '--r', linewidth=2)\n",
    "            plt.title(f'{model_name}\\nR2: {r2:.2f} | RMSE: {rmse_kwh:.2f} | MAE: {mae_kwh:.2f} kWh')\n",
    "            plt.xlabel('Nilai Aktual (kWh)')\n",
    "            plt.ylabel('Nilai Prediksi (kWh)')\n",
    "            plt.grid(True)\n",
    "        plt.suptitle(f'Scatter Plot Zoom (500 Data Terakhir) - {plot_suffix}', fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.savefig(os.path.join(output_dir, f'scatter_plot_zoom_{plot_suffix}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    # --- Grafik Waktu (Titik Acak) ---\n",
    "    plot_df_full.sort_index(inplace=True)\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(plot_df_full.index, plot_df_full['Aktual (kWh)'], label='Nilai Aktual', color='blue', marker='o', linestyle='None', markersize=5, alpha=0.8)\n",
    "    plt.plot(plot_df_full.index, plot_df_full['RandomForest'], label='Prediksi RF', color='green', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "    plt.plot(plot_df_full.index, plot_df_full['GradientBoosting'], label='Prediksi GB', color='red', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "    plt.plot(plot_df_full.index, plot_df_full['LSTM'], label='Prediksi LSTM', color='orange', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "    plt.title(f'Grafik Waktu: Prediksi vs Aktual - {plot_suffix}\\n(Menampilkan titik data dari Test Set yang acak)', fontsize=16)\n",
    "    plt.xlabel('Waktu'); plt.ylabel('Konsumsi Energi (kWh)')\n",
    "    plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'time_series_plot_{plot_suffix}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # --- Grafik Waktu Zoom (500 Data Terakhir) ---\n",
    "    if not plot_df_zoom.empty:\n",
    "        plt.figure(figsize=(20, 8))\n",
    "        plt.plot(plot_df_zoom.index, plot_df_zoom['Aktual (kWh)'], label='Nilai Aktual', color='blue', marker='o', linestyle='None', markersize=5, alpha=0.8)\n",
    "        plt.plot(plot_df_zoom.index, plot_df_zoom['RandomForest'], label='Prediksi RF', color='green', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "        plt.plot(plot_df_zoom.index, plot_df_zoom['GradientBoosting'], label='Prediksi GB', color='red', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "        plt.plot(plot_df_zoom.index, plot_df_zoom['LSTM'], label='Prediksi LSTM', color='orange', marker='x', linestyle='None', markersize=4, alpha=0.8)\n",
    "        plt.title(f'Grafik Waktu Zoom (500 Data Terakhir) - {plot_suffix}', fontsize=16)\n",
    "        plt.xlabel('Waktu'); plt.ylabel('Konsumsi Energi (kWh)')\n",
    "        plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'time_series_plot_zoom_{plot_suffix}.png'))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def create_combined_heatmap(performance_data, title_suffix, output_dir):\n",
    "    \"\"\"Membuat dan menyimpan heatmap gabungan dari data kinerja model.\"\"\"\n",
    "    if not performance_data:\n",
    "        print(f\"Tidak ada data kinerja untuk membuat heatmap.\")\n",
    "        return\n",
    "    df = pd.DataFrame(performance_data)\n",
    "\n",
    "    df['Label Perangkat'] = df['Gedung'] + ' - ' + df['Perangkat']\n",
    "    try:\n",
    "        df.sort_values(by=['Gedung', 'Label Perangkat'], inplace=True)\n",
    "        mae_pivot = df.pivot_table(index='Model', columns='Label Perangkat', values='MAE')\n",
    "        rmse_pivot = df.pivot_table(index='Model', columns='Label Perangkat', values='RMSE')\n",
    "        r2_pivot = df.pivot_table(index='Model', columns='Label Perangkat', values='R2')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat membuat pivot table untuk {title_suffix}: {e}\\nData: {df}\")\n",
    "        return\n",
    "\n",
    "    num_devices = len(df['Label Perangkat'].unique())\n",
    "    fig_width = max(18, num_devices * 1.5)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(fig_width, 21))\n",
    "    fig.suptitle(f'Heatmap Kinerja Model - {title_suffix}', fontsize=20)\n",
    "\n",
    "    # Heatmap R2\n",
    "    sns.heatmap(r2_pivot, annot=True, fmt=\".2f\", cmap=\"viridis\", ax=axes[0], linewidths=.5)\n",
    "    axes[0].set_title('R2 Score - Lebih Tinggi Lebih Baik', fontsize=16)\n",
    "    axes[0].set_xlabel(''); axes[0].set_ylabel('Model', fontsize=12)\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Heatmap RMSE\n",
    "    sns.heatmap(rmse_pivot, annot=True, fmt=\".2f\", cmap=\"viridis_r\", ax=axes[1], linewidths=.5)\n",
    "    axes[1].set_title('RMSE (kWh) - Lebih Rendah Lebih Baik', fontsize=16)\n",
    "    axes[1].set_xlabel(''); axes[1].set_ylabel('Model', fontsize=12)\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Heatmap MAE\n",
    "    sns.heatmap(mae_pivot, annot=True, fmt=\".2f\", cmap=\"viridis_r\", ax=axes[2], linewidths=.5)\n",
    "    axes[2].set_title('MAE (kWh) - Lebih Rendah Lebih Baik', fontsize=16)\n",
    "    axes[2].set_xlabel('Gedung - Perangkat / Lokasi', fontsize=12)\n",
    "    axes[2].set_ylabel('Model', fontsize=12)\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    heatmap_path = os.path.join(output_dir, f'heatmap_{title_suffix}.png')\n",
    "    plt.savefig(heatmap_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"\\nHeatmap gabungan disimpan di: {heatmap_path}\")\n",
    "\n",
    "print(\"✅ Fungsi-fungsi pembantu berhasil didefinisikan.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 5. Memuat, Membersihkan, dan Menggabungkan Data\n",
    "# ==============================================================================\n",
    "# Sel ini akan memuat semua data, membersihkannya, dan menggabungkannya\n",
    "# berdasarkan jenis perangkat di setiap gedung.\n",
    "\n",
    "grouped_data = {}\n",
    "consumption_ranking = []\n",
    "\n",
    "print(\"Memulai proses pemuatan dan penggabungan data...\")\n",
    "for root, dirs, files in os.walk(SOURCE_DATA_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, index_col='id_time', parse_dates=True)\n",
    "\n",
    "                if TARGET_VARIABLE not in df.columns or df[TARGET_VARIABLE].isnull().all():\n",
    "                    continue\n",
    "\n",
    "                df_cleaned = df[[TARGET_VARIABLE]].dropna()\n",
    "                df_cleaned = df_cleaned[df_cleaned[TARGET_VARIABLE] > 0]\n",
    "\n",
    "                if not df_cleaned.empty:\n",
    "                    path_parts = os.path.relpath(root, SOURCE_DATA_DIR).split(os.sep)\n",
    "                    building = path_parts[0]\n",
    "                    device_label = \"_\".join(path_parts[1:])\n",
    "                    avg_consumption = df_cleaned[TARGET_VARIABLE].mean()\n",
    "                    consumption_ranking.append({\n",
    "                        'label': f\"{building} - {device_label}\",\n",
    "                        'avg_kwh': avg_consumption / 1000\n",
    "                    })\n",
    "\n",
    "                path_parts = os.path.relpath(root, SOURCE_DATA_DIR).split(os.sep)\n",
    "                building = path_parts[0]\n",
    "                device_type = path_parts[-1].split('_')[0].lower()\n",
    "\n",
    "                group_key = f\"{building}_{device_type}\"\n",
    "\n",
    "                if group_key not in grouped_data:\n",
    "                    grouped_data[group_key] = []\n",
    "\n",
    "                grouped_data[group_key].append(df)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   - Gagal memproses {file_path}: {e}\")\n",
    "\n",
    "for key, df_list in grouped_data.items():\n",
    "    grouped_data[key] = pd.concat(df_list, ignore_index=False)\n",
    "    print(f\"✅ Data untuk '{key}' berhasil digabungkan, total {len(grouped_data[key])} baris.\")\n",
    "\n",
    "print(\"\\n--- Peringkat Konsumsi Energi Rata-Rata Terbesar ---\")\n",
    "consumption_ranking.sort(key=lambda x: x['avg_kwh'], reverse=True)\n",
    "for i, item in enumerate(consumption_ranking):\n",
    "    print(f\"{i+1}. {item['label']}: {item['avg_kwh']:.2f} kWh\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 6. Proses Utama: Melatih Model per Jenis Perangkat\n",
    "# ==============================================================================\n",
    "# Sel ini akan melakukan loop melalui data yang sudah digabungkan,\n",
    "# melatih model, dan menyimpan hasilnya.\n",
    "\n",
    "best_model_counter = Counter()\n",
    "all_model_stats = []\n",
    "total_models_trained = 0\n",
    "building_predictions_tracker = {}\n",
    "\n",
    "# PEMBARUAN: Inisialisasi daftar hari libur Indonesia\n",
    "# Ambil tahun unik dari data untuk mendapatkan hari libur yang relevan\n",
    "all_years = []\n",
    "for df_group in grouped_data.values():\n",
    "    all_years.extend(df_group.index.year.unique())\n",
    "unique_years = sorted(list(set(all_years)))\n",
    "id_holidays = holidays.Indonesia(years=unique_years)\n",
    "print(f\"\\n📅 Mengambil data hari libur nasional Indonesia untuk tahun: {unique_years}\")\n",
    "\n",
    "\n",
    "for group_name, df_group in grouped_data.items():\n",
    "    print(f\"\\n{'='*50}\\nMemproses Grup: {group_name.upper()}\\n{'='*50}\")\n",
    "\n",
    "    existing_cols = [col for col in RELEVANT_COLUMNS if col in df_group.columns]\n",
    "    df_processed = df_group.reindex(columns=existing_cols).copy()\n",
    "    df_processed.dropna(subset=[TARGET_VARIABLE], inplace=True)\n",
    "\n",
    "    # --- Penanganan Fitur ---\n",
    "    # 1. Tambahkan fitur lag 1 jam, yang akan selalu digunakan\n",
    "    df_processed['Konsumsi_Energi_Lag_1'] = df_processed[TARGET_VARIABLE].shift(1)\n",
    "    \n",
    "    # --- PEMBARUAN: Tambahkan Fitur Hari Libur dan Akhir Pekan ---\n",
    "    # Cek apakah hari adalah Sabtu (5) atau Minggu (6)\n",
    "    df_processed['is_weekend'] = (df_processed.index.dayofweek >= 5).astype(int)\n",
    "    # Cek apakah tanggal ada di daftar hari libur nasional\n",
    "    df_processed['isHoliday'] = df_processed.index.isin(id_holidays).astype(int)\n",
    "    print(f\"   - Menambahkan fitur 'is_weekend' dan 'isHoliday'.\")\n",
    "\n",
    "    # 2. Ubah 'Wind Direction' menjadi komponen sinus dan kosinus\n",
    "    if 'Wind Direction' in df_processed.columns:\n",
    "        df_processed['Wind_Direction_sin'] = np.sin(np.deg2rad(df_processed['Wind Direction']))\n",
    "        df_processed['Wind_Direction_cos'] = np.cos(np.deg2rad(df_processed['Wind Direction']))\n",
    "        df_processed.drop('Wind Direction', axis=1, inplace=True)\n",
    "\n",
    "    # 3. Terapkan one-hot encoding pada 'Weather Code'\n",
    "    if 'Weather Code' in df_processed.columns:\n",
    "        df_processed = pd.get_dummies(df_processed, columns=['Weather Code'], prefix='WeatherCode')\n",
    "\n",
    "    # Hapus baris dengan NaN yang mungkin muncul dari fitur lag\n",
    "    df_processed.dropna(inplace=True)\n",
    "    df_final = df_processed[df_processed[TARGET_VARIABLE] > 0].copy()\n",
    "\n",
    "    if len(df_final) < MINIMUM_ROWS:\n",
    "        print(f\"   - ⚠️ PERINGATAN: Data tidak cukup ({len(df_final)} baris). Melewati pelatihan untuk grup ini.\")\n",
    "        continue\n",
    "\n",
    "    # --- PEMBARUAN: Logika Seleksi Fitur Baru ---\n",
    "    print(\"\\n   --- Memulai Seleksi Fitur ---\")\n",
    "    correlation_matrix = df_final.corr(method='spearman')\n",
    "\n",
    "    output_dir = os.path.join(RESULTS_DIR, *group_name.split('_'))\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Simpan heatmap korelasi\n",
    "    show_annotations = len(correlation_matrix.columns) < 40\n",
    "    plt.figure(figsize=(22, 18))\n",
    "    sns.heatmap(correlation_matrix, annot=show_annotations, cmap='coolwarm', fmt=\".2f\")\n",
    "    plt.title(f'Correlation Matrix (Spearman) - {group_name}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'correlation_matrix_{group_name}.png'))\n",
    "    plt.close()\n",
    "    print(f\"   - Heatmap korelasi disimpan di: {output_dir}\")\n",
    "\n",
    "    # 1. TAHAP 1: Analisis Multikolinearitas (diluar fitur target dan lag)\n",
    "    potential_features = [col for col in df_final.columns if col not in [TARGET_VARIABLE, 'Konsumsi_Energi_Lag_1']]\n",
    "    feature_corr_matrix = df_final[potential_features].corr().abs()\n",
    "    \n",
    "    upper_tri = feature_corr_matrix.where(np.triu(np.ones(feature_corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] >= 0.8)]\n",
    "    \n",
    "    independent_features = [f for f in potential_features if f not in to_drop]\n",
    "    print(f\"   - Tahap 1: Ditemukan {len(to_drop)} fitur dengan multikolinearitas (dihapus): {to_drop}\")\n",
    "    print(f\"   - Tahap 1: Terdapat {len(independent_features)} fitur independen yang tersisa.\")\n",
    "\n",
    "    # 2. TAHAP 2: Analisis Korelasi dengan Target dari Fitur Independen (THRESHOLD DINAMIS)\n",
    "    highly_correlated_features = []\n",
    "    if independent_features:\n",
    "        target_correlations = correlation_matrix.loc[independent_features, TARGET_VARIABLE]\n",
    "        # Coba threshold 0.4 terlebih dahulu\n",
    "        highly_correlated_features = target_correlations[\n",
    "            (target_correlations >= 0.4) | (target_correlations <= -0.4)\n",
    "        ].index.tolist()\n",
    "        \n",
    "        # Jika tidak ada, turunkan threshold ke 0.3\n",
    "        if not highly_correlated_features:\n",
    "            print(f\"   - Tahap 2: Tidak ditemukan fitur dengan korelasi |r| >= 0.4. Menurunkan threshold ke 0.3...\")\n",
    "            highly_correlated_features = target_correlations[\n",
    "                (target_correlations >= 0.3) | (target_correlations <= -0.3)\n",
    "            ].index.tolist()\n",
    "            print(f\"   - Tahap 2 (Revisi): Ditemukan {len(highly_correlated_features)} fitur dengan korelasi |r| >= 0.3: {highly_correlated_features}\")\n",
    "        else:\n",
    "            print(f\"   - Tahap 2: Ditemukan {len(highly_correlated_features)} fitur independen yang berkorelasi kuat dengan target (|r| >= 0.4): {highly_correlated_features}\")\n",
    "\n",
    "    # 3. TAHAP 3: Fitur Terpilih Final\n",
    "    # Memulai dengan fitur lag dan fitur yang berkorelasi tinggi\n",
    "    final_features = ['Konsumsi_Energi_Lag_1'] + highly_correlated_features\n",
    "\n",
    "    # PEMBARUAN: Logika baru untuk fitur weekend dan holiday dengan threshold 0.3\n",
    "    # Hanya tambahkan 'is_weekend' jika korelasinya >= 0.3\n",
    "    if 'is_weekend' in independent_features:\n",
    "        weekend_corr = abs(target_correlations.get('is_weekend', 0))\n",
    "        if weekend_corr >= 0.3:\n",
    "            final_features.append('is_weekend')\n",
    "            print(f\"   - Fitur 'is_weekend' ditambahkan (korelasi: {weekend_corr:.2f}).\")\n",
    "        else:\n",
    "            print(f\"   - Fitur 'is_weekend' dilewati (korelasi: {weekend_corr:.2f} < 0.3).\")\n",
    "\n",
    "\n",
    "    # Hanya tambahkan 'isHoliday' jika korelasinya >= 0.3\n",
    "    if 'isHoliday' in independent_features:\n",
    "        holiday_corr = abs(target_correlations.get('isHoliday', 0))\n",
    "        if holiday_corr >= 0.3:\n",
    "            final_features.append('isHoliday')\n",
    "            print(f\"   - Fitur 'isHoliday' ditambahkan (korelasi: {holiday_corr:.2f}).\")\n",
    "        else:\n",
    "            print(f\"   - Fitur 'isHoliday' dilewati (korelasi: {holiday_corr:.2f} < 0.3).\")\n",
    "        \n",
    "    features_for_model = list(dict.fromkeys(final_features)) # Pastikan tidak ada duplikat\n",
    "\n",
    "    print(f\"   - Tahap 3: Fitur final untuk model: {features_for_model}\\n\")\n",
    "    \n",
    "    # Simpan fitur terpilih ke CSV\n",
    "    pd.DataFrame({'fitur_terpilih': features_for_model}).to_csv(os.path.join(output_dir, f'fitur_terpilih_{group_name}.csv'), index=False)\n",
    "\n",
    "    if not features_for_model:\n",
    "        print(\"   - Tidak ada fitur sama sekali untuk model. Melewati grup ini.\"); continue\n",
    "\n",
    "    X = df_final[features_for_model]; y = df_final[TARGET_VARIABLE]\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    if len(X_train) == 0 or len(X_test) == 0: continue\n",
    "\n",
    "    print(f\"   - Ukuran Data: Latih={len(X_train)}, Validasi={len(X_val)}, Uji={len(X_test)} (Acak)\")\n",
    "    model_evaluations = train_and_evaluate_models(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "    device_predictions = {name: data['predictions'] for name, data in model_evaluations.items()}\n",
    "    create_prediction_plots(y_test, device_predictions, group_name, output_dir)\n",
    "    print(f\"   - Plot prediksi untuk grup '{group_name}' disimpan.\")\n",
    "\n",
    "    building_name, device_type = group_name.split('_', 1)\n",
    "    if building_name not in building_predictions_tracker:\n",
    "        building_predictions_tracker[building_name] = {'y_true': [], 'preds': {'RandomForest': [], 'GradientBoosting': [], 'LSTM': []}}\n",
    "\n",
    "    building_predictions_tracker[building_name]['y_true'].append(y_test)\n",
    "    for model_name, preds in device_predictions.items():\n",
    "        building_predictions_tracker[building_name]['preds'][model_name].append(preds)\n",
    "\n",
    "    best_model_name, best_model_mae = '', float('inf')\n",
    "    for model_name, eval_data in model_evaluations.items():\n",
    "        if eval_data['mae'] < best_model_mae:\n",
    "            best_model_mae = eval_data['mae']\n",
    "            best_model_name = model_name\n",
    "\n",
    "        all_model_stats.append({\n",
    "            'Gedung': building_name,\n",
    "            'Perangkat': device_type,\n",
    "            'Model': model_name,\n",
    "            'MAE': eval_data['mae'] / 1000,\n",
    "            'RMSE': eval_data['rmse'] / 1000,\n",
    "            'R2': eval_data['r2']\n",
    "        })\n",
    "\n",
    "    best_model_counter[best_model_name] += 1\n",
    "    total_models_trained += 1\n",
    "    print(f\"   ==> Model terbaik untuk grup ini adalah {best_model_name} (berdasarkan MAE).\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 7. Ringkasan dan Analisis Final\n",
    "# ==============================================================================\n",
    "# Sel ini akan menampilkan ringkasan model terbaik dan statistik evaluasi.\n",
    "\n",
    "if total_models_trained > 0:\n",
    "    stats_df = pd.DataFrame(all_model_stats)\n",
    "    stats_df.to_csv(os.path.join(RESULTS_DIR, 'laporan_kinerja_semua_model.csv'), index=False)\n",
    "    print(f\"\\n✅ Laporan kinerja lengkap disimpan di: {os.path.join(RESULTS_DIR, 'laporan_kinerja_semua_model.csv')}\")\n",
    "\n",
    "\n",
    "    # --- 1. Ringkasan Model Terbaik ---\n",
    "    print(f\"\\n{'='*50}\\nRingkasan Model Terbaik (dari {total_models_trained} grup perangkat)\\n{'='*50}\")\n",
    "    sorted_models = best_model_counter.most_common()\n",
    "    for model, count in sorted_models:\n",
    "        percentage = (count / total_models_trained) * 100\n",
    "        print(f\"🏆 {model}: Model terbaik sebanyak {count}/{total_models_trained} kali ({percentage:.1f}%)\")\n",
    "\n",
    "    # --- 2. Statistik Evaluasi Keseluruhan ---\n",
    "    print(f\"\\n{'='*50}\\nStatistik Evaluasi Keseluruhan (Rata-rata dari semua model)\\n{'='*50}\")\n",
    "    overall_avg = stats_df[['R2', 'RMSE', 'MAE']].mean()\n",
    "    print(f\"Rata-rata R2 Score : {overall_avg['R2']:.2f}\")\n",
    "    print(f\"Rata-rata RMSE     : {overall_avg['RMSE']:.2f} kWh\")\n",
    "    print(f\"Rata-rata MAE      : {overall_avg['MAE']:.2f} kWh\")\n",
    "\n",
    "    # --- 3. Rata-Rata Metrik per Model ---\n",
    "    print(f\"\\n{'='*50}\\nRata-Rata Metrik per Model\\n{'='*50}\")\n",
    "    per_model_avg = stats_df.groupby('Model')[['R2', 'RMSE', 'MAE']].mean()\n",
    "    print(per_model_avg.round(2))\n",
    "\n",
    "    # --- 4. Detail Metrik Evaluasi per Grup Perangkat ---\n",
    "    print(f\"\\n{'='*50}\\nDetail Metrik Evaluasi per Grup Perangkat\\n{'='*50}\")\n",
    "    for group, group_df in stats_df.groupby(['Gedung', 'Perangkat']):\n",
    "        print(f\"\\n--- Grup: {group[0].upper()} - {group[1].upper()} ---\")\n",
    "        best_model_in_group = group_df.loc[group_df['MAE'].idxmin()]\n",
    "        for index, row in group_df.iterrows():\n",
    "            is_best = \"🏆\" if row['Model'] == best_model_in_group['Model'] else \"\"\n",
    "            print(f\"  - Model: {row['Model']:<17} | R2: {row['R2']:.2f} | RMSE: {row['RMSE']:.2f} kWh | MAE: {row['MAE']:.2f} kWh {is_best}\")\n",
    "\n",
    "    # --- 5. Membuat Plot Gabungan per Gedung ---\n",
    "    print(f\"\\n{'='*50}\\nMembuat Plot Gabungan per Gedung\\n{'='*50}\")\n",
    "    for building_name, data in building_predictions_tracker.items():\n",
    "        y_true_combined = pd.concat(data['y_true'])\n",
    "        preds_combined = {model: np.concatenate(preds) for model, preds in data['preds'].items()}\n",
    "\n",
    "        building_output_dir = os.path.join(RESULTS_DIR, building_name)\n",
    "        os.makedirs(building_output_dir, exist_ok=True)\n",
    "\n",
    "        create_prediction_plots(y_true_combined, preds_combined, f\"Gabungan_{building_name.upper()}\", building_output_dir)\n",
    "        print(f\"✅ Plot prediksi gabungan untuk gedung '{building_name}' disimpan di: {building_output_dir}\")\n",
    "        \n",
    "    # --- 6. Membuat Heatmap Kinerja Gabungan ---\n",
    "    print(f\"\\n{'='*50}\\nMembuat Heatmap Kinerja Gabungan\\n{'='*50}\")\n",
    "    create_combined_heatmap(all_model_stats, \"Kinerja_Gabungan_Semua_Gedung\", RESULTS_DIR)\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"\\nTidak ada model yang dilatih, ringkasan tidak dapat dibuat.\")\n",
    "\n",
    "print(f\"\\n\\n🏁 Proses Selesai. Semua hasil telah disimpan di folder '{RESULTS_DIR}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
