{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6136151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Library berhasil diimpor.\n",
      "📁 Folder sumber data diatur ke: 'sumber_data'\n",
      "📁 Folder hasil akan disimpan di: 'hasil_model_notshuffled'\n",
      "✅ Sel ini siap.\n",
      "Pastikan Anda telah mengunggah data Anda ke dalam folder 'sumber_data'.\n",
      "✅ Fungsi-fungsi pembantu berhasil didefinisikan.\n",
      "\n",
      "==================================================\n",
      "Memproses file: sumber_data/witel/lantai1/ahu/Cleaned_Cleaned_WITEL_AHU_L1_hasil_interpolasi_1_Jam.csv\n",
      "==================================================\n",
      "   - Membuat fitur historis dari Konsumsi Energi...\n",
      "   - Jumlah data sebelum pembersihan NaN: 8784\n",
      "   - Jumlah data setelah pembersihan NaN: 5772\n",
      "   - Jumlah data sebelum filter nilai 0: 5772\n",
      "   - Jumlah data setelah filter nilai 0: 5245\n",
      "   - Verifikasi: Nilai minimum 'Konsumsi Energi' setelah filter adalah 100.0000\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_notshuffled/witel/lantai1/ahu\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Temperature', 'Relative Humidity', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Sunshine Duration', 'UV Index', 'Direct Radiation', 'Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=4012, Validasi=446, Uji=787 (Berurutan)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step \n",
      "   - Plot prediksi untuk perangkat 'ahu' disimpan.\n",
      "   ==> Model terbaik (GradientBoosting) disimpan.\n",
      "\n",
      "==================================================\n",
      "Memproses file: sumber_data/witel/lantai1/sdp/Cleaned_Cleaned_WITEL_SDP_L1_hasil_interpolasi_1_Jam.csv\n",
      "==================================================\n",
      "   - Membuat fitur historis dari Konsumsi Energi...\n",
      "   - Jumlah data sebelum pembersihan NaN: 8784\n",
      "   - Jumlah data setelah pembersihan NaN: 6827\n",
      "   - Jumlah data sebelum filter nilai 0: 6827\n",
      "   - Jumlah data setelah filter nilai 0: 6827\n",
      "   - Verifikasi: Nilai minimum 'Konsumsi Energi' setelah filter adalah 3000.0000\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_notshuffled/witel/lantai1/sdp\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Temperature', 'Relative Humidity', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Sunshine Duration', 'UV Index', 'Direct Radiation', 'Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=5221, Validasi=581, Uji=1025 (Berurutan)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Plot prediksi untuk perangkat 'sdp' disimpan.\n",
      "   ==> Model terbaik (LSTM) disimpan.\n",
      "\n",
      "==================================================\n",
      "Memproses file: sumber_data/witel/lantai2/ahu/Cleaned_Cleaned_WITEL_AHU_L2_hasil_interpolasi_1_Jam.csv\n",
      "==================================================\n",
      "   - Membuat fitur historis dari Konsumsi Energi...\n",
      "   - Jumlah data sebelum pembersihan NaN: 8784\n",
      "   - Jumlah data setelah pembersihan NaN: 6730\n",
      "   - Jumlah data sebelum filter nilai 0: 6730\n",
      "   - Jumlah data setelah filter nilai 0: 6727\n",
      "   - Verifikasi: Nilai minimum 'Konsumsi Energi' setelah filter adalah 100.0000\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_notshuffled/witel/lantai2/ahu\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Temperature', 'Relative Humidity', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Sunshine Duration', 'UV Index', 'Direct Radiation', 'Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=5145, Validasi=572, Uji=1010 (Berurutan)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Plot prediksi untuk perangkat 'ahu' disimpan.\n",
      "   ==> Model terbaik (LSTM) disimpan.\n",
      "\n",
      "==================================================\n",
      "Memproses file: sumber_data/witel/lantai2/sdp/Cleaned_Cleaned_WITEL_SDP_L2_hasil_interpolasi_1_Jam.csv\n",
      "==================================================\n",
      "   - Membuat fitur historis dari Konsumsi Energi...\n",
      "   - Jumlah data sebelum pembersihan NaN: 8778\n",
      "   - Jumlah data setelah pembersihan NaN: 5151\n",
      "   - Jumlah data sebelum filter nilai 0: 5151\n",
      "   - Jumlah data setelah filter nilai 0: 5151\n",
      "   - Verifikasi: Nilai minimum 'Konsumsi Energi' setelah filter adalah 700.0000\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_notshuffled/witel/lantai2/sdp\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Evapotranspiration', 'Sunshine Duration', 'Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=3940, Validasi=438, Uji=773 (Berurutan)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Plot prediksi untuk perangkat 'sdp' disimpan.\n",
      "   ==> Model terbaik (LSTM) disimpan.\n",
      "\n",
      "==================================================\n",
      "Memproses file: sumber_data/witel/lift/Cleaned_WITEL_LIFT_hasil_interpolasi_1_Jam.csv\n",
      "==================================================\n",
      "   - Membuat fitur historis dari Konsumsi Energi...\n",
      "   - Jumlah data sebelum pembersihan NaN: 8777\n",
      "   - Jumlah data setelah pembersihan NaN: 5424\n",
      "   - Jumlah data sebelum filter nilai 0: 5424\n",
      "   - Jumlah data setelah filter nilai 0: 5424\n",
      "   - Verifikasi: Nilai minimum 'Konsumsi Energi' setelah filter adalah 1700.0000\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_notshuffled/witel/lift\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Temperature', 'Relative Humidity', 'Evapotranspiration', 'Vapour Pressure Deficit', 'Wind Gusts', 'Sunshine Duration', 'UV Index', 'Direct Radiation', 'Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=4149, Validasi=461, Uji=814 (Berurutan)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "   - Plot prediksi untuk perangkat 'lift' disimpan.\n",
      "   ==> Model terbaik (GradientBoosting) disimpan.\n",
      "\n",
      "==================================================\n",
      "Memproses file: sumber_data/witel/lantai3/ahu/Cleaned_Cleaned_WITEL_AHU_L3_hasil_interpolasi_1_Jam.csv\n",
      "==================================================\n",
      "   - Membuat fitur historis dari Konsumsi Energi...\n",
      "   - Jumlah data sebelum pembersihan NaN: 8784\n",
      "   - Jumlah data setelah pembersihan NaN: 5328\n",
      "   - Jumlah data sebelum filter nilai 0: 5328\n",
      "   - Jumlah data setelah filter nilai 0: 5328\n",
      "   - Verifikasi: Nilai minimum 'Konsumsi Energi' setelah filter adalah 100.0000\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_notshuffled/witel/lantai3/ahu\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Temperature', 'Evapotranspiration', 'Sunshine Duration', 'UV Index', 'Direct Radiation', 'Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=4075, Validasi=453, Uji=800 (Berurutan)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n",
      "   - Melatih LSTM...\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "   - Plot prediksi untuk perangkat 'ahu' disimpan.\n",
      "   ==> Model terbaik (GradientBoosting) disimpan.\n",
      "\n",
      "==================================================\n",
      "Memproses file: sumber_data/witel/lantai3/sdp/Cleaned_Cleaned_WITEL_SDP_L3_hasil_interpolasi_1_Jam.csv\n",
      "==================================================\n",
      "   - Membuat fitur historis dari Konsumsi Energi...\n",
      "   - Jumlah data sebelum pembersihan NaN: 8777\n",
      "   - Jumlah data setelah pembersihan NaN: 5538\n",
      "   - Jumlah data sebelum filter nilai 0: 5538\n",
      "   - Jumlah data setelah filter nilai 0: 5537\n",
      "   - Verifikasi: Nilai minimum 'Konsumsi Energi' setelah filter adalah 1000.0000\n",
      "   - Menghitung matriks korelasi...\n",
      "   - Heatmap korelasi disimpan di: hasil_model_notshuffled/witel/lantai3/sdp\n",
      "   - Fitur terpilih dengan korelasi >= 0.4: ['Temperature', 'Evapotranspiration', 'Konsumsi_Energi_Lag_1', 'Konsumsi_Energi_Lag_2', 'Konsumsi_Energi_Lag_3']\n",
      "   - Ukuran Data: Latih=4235, Validasi=471, Uji=831 (Berurutan)\n",
      "   - Melatih Random Forest...\n",
      "   - Melatih Gradient Boosting...\n"
     ]
    }
   ],
   "source": [
    "# ==\"\"\"\n",
    "# ==============================================================================\n",
    "# @title 1. Instalasi dan Impor Library\n",
    "# ==============================================================================\n",
    "# Jalankan sel ini terlebih dahulu untuk mengimpor semua library yang dibutuhkan.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"✅ Library berhasil diimpor.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 2. Konfigurasi Utama\n",
    "# ==============================================================================\n",
    "# Sel ini mendefinisikan variabel-variabel penting seperti lokasi folder\n",
    "# dan daftar kolom yang akan digunakan dalam model.\n",
    "\n",
    "# Tentukan path folder sumber data dan folder untuk menyimpan hasil\n",
    "SOURCE_DATA_DIR = 'sumber_data'\n",
    "RESULTS_DIR = 'hasil_model_notshuffled'\n",
    "\n",
    "# Pastikan folder hasil utama dan folder sumber ada\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(SOURCE_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Daftar kolom fitur yang akan digunakan (tanpa 'Apparent Temperature')\n",
    "RELEVANT_COLUMNS = [\n",
    "    'Konsumsi Energi', 'Temperature', 'Showers', 'Cloud Cover', 'Weather Code',\n",
    "    'Relative Humidity', 'Dew Point', 'Precipitation',\n",
    "    'Pressure MSL', 'Surface Pressure', 'Evapotranspiration',\n",
    "    'Vapour Pressure Deficit', 'Wind Speed', 'Wind Direction', 'Wind Gusts',\n",
    "    'Soil Temperature', 'Sunshine Duration', 'UV Index', 'Direct Radiation'\n",
    "]\n",
    "TARGET_VARIABLE = 'Konsumsi Energi'\n",
    "\n",
    "print(f\"📁 Folder sumber data diatur ke: '{SOURCE_DATA_DIR}'\")\n",
    "print(f\"📁 Folder hasil akan disimpan di: '{RESULTS_DIR}'\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 3. Persiapan Folder dan Unggah Data\n",
    "# ==============================================================================\n",
    "# PENTING: Sebelum menjalankan sel-sel berikutnya, unggah data Anda.\n",
    "#\n",
    "# 1. Di panel file sebelah kiri Google Colab, Anda akan melihat folder 'sumber_data'.\n",
    "# 2. Klik kanan pada folder 'sumber_data' tersebut dan pilih 'Upload'.\n",
    "# 3. Unggah folder 'witel' dan 'opmc' Anda yang berisi semua data CSV\n",
    "#    ke dalam folder 'sumber_data'.\n",
    "#\n",
    "# Setelah selesai, Anda bisa melanjutkan menjalankan sel-sel berikutnya.\n",
    "\n",
    "print(\"✅ Sel ini siap.\")\n",
    "print(f\"Pastikan Anda telah mengunggah data Anda ke dalam folder '{SOURCE_DATA_DIR}'.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 4. Definisi Fungsi-Fungsi Pembantu\n",
    "# ==============================================================================\n",
    "# Sel ini berisi fungsi-fungsi utama untuk melatih model dan membuat visualisasi.\n",
    "# Jalankan sel ini untuk mendefinisikan fungsi agar bisa digunakan nanti.\n",
    "\n",
    "def train_and_evaluate_models(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melatih semua model (RF, GB, LSTM) dan mengembalikan\n",
    "    prediksi serta metrik kinerjanya.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # --- Model 1: Random Forest Regressor ---\n",
    "    print(\"   - Melatih Random Forest...\")\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    results['RandomForest'] = {\n",
    "        'model': rf_model, \n",
    "        'predictions': y_pred_rf, \n",
    "        'mae': mean_absolute_error(y_test, y_pred_rf),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_test, y_pred_rf)), \n",
    "        'r2': r2_score(y_test, y_pred_rf)\n",
    "    }\n",
    "\n",
    "    # --- Model 2: Gradient Boosting Regressor ---\n",
    "    print(\"   - Melatih Gradient Boosting...\")\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    y_pred_gb = gb_model.predict(X_test)\n",
    "    results['GradientBoosting'] = {\n",
    "        'model': gb_model, \n",
    "        'predictions': y_pred_gb, \n",
    "        'mae': mean_absolute_error(y_test, y_pred_gb),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_test, y_pred_gb)), \n",
    "        'r2': r2_score(y_test, y_pred_gb)\n",
    "    }\n",
    "\n",
    "    # --- Model 3: LSTM ---\n",
    "    print(\"   - Melatih LSTM...\")\n",
    "    scaler_X = MinMaxScaler(feature_range=(0, 1)); scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train); y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "    X_val_scaled = scaler_X.transform(X_val); y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1))\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "    X_val_lstm = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
    "    X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "    lstm_model = Sequential([LSTM(50, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])), Dense(1)])\n",
    "    lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    lstm_model.fit(X_train_lstm, y_train_scaled, epochs=50, batch_size=32, validation_data=(X_val_lstm, y_val_scaled), verbose=0, shuffle=False)\n",
    "    y_pred_lstm_scaled = lstm_model.predict(X_test_lstm)\n",
    "    y_pred_lstm = scaler_y.inverse_transform(y_pred_lstm_scaled)\n",
    "    results['LSTM'] = {\n",
    "        'model': lstm_model, \n",
    "        'predictions': y_pred_lstm.flatten(), \n",
    "        'mae': mean_absolute_error(y_test, y_pred_lstm),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_test, y_pred_lstm)), \n",
    "        'r2': r2_score(y_test, y_pred_lstm)\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def create_prediction_plots(y_test, predictions, plot_suffix, output_dir):\n",
    "    \"\"\"Membuat dan menyimpan scatter plot dan line graph untuk prediksi.\"\"\"\n",
    "    # --- Konversi ke kWh untuk semua plot ---\n",
    "    y_test_kwh = y_test / 1000\n",
    "    predictions_kwh = {name: pred / 1000 for name, pred in predictions.items()}\n",
    "\n",
    "    # --- Scatter Plot ---\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    colors = ['green', 'red', 'orange']\n",
    "    for i, (model_name, pred_kwh) in enumerate(predictions_kwh.items()):\n",
    "        mae_kwh = mean_absolute_error(y_test_kwh, pred_kwh)\n",
    "        rmse_kwh = np.sqrt(mean_squared_error(y_test_kwh, pred_kwh))\n",
    "        r2 = r2_score(y_test_kwh, pred_kwh)\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.scatter(y_test_kwh, pred_kwh, alpha=0.6, edgecolors='k', color=colors[i])\n",
    "        plt.plot([y_test_kwh.min(), y_test_kwh.max()], [y_test_kwh.min(), y_test_kwh.max()], '--r', linewidth=2)\n",
    "        plt.title(f'{model_name}\\nR2: {r2:.2f} | RMSE: {rmse_kwh:.2f} | MAE: {mae_kwh:.2f} kWh')\n",
    "        plt.xlabel('Nilai Aktual (kWh)')\n",
    "        plt.ylabel('Nilai Prediksi (kWh)')\n",
    "        plt.grid(True)\n",
    "    plt.suptitle(f'Scatter Plot - {plot_suffix}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(os.path.join(output_dir, f'scatter_plot_{plot_suffix}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # --- Grafik Garis Waktu ---\n",
    "    plot_df = pd.DataFrame({'Aktual (kWh)': y_test_kwh})\n",
    "    for model_name, pred_kwh in predictions_kwh.items():\n",
    "        plot_df[f'Prediksi {model_name} (kWh)'] = pred_kwh\n",
    "    \n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(plot_df.index, plot_df['Aktual (kWh)'], label='Nilai Aktual (Test Set)', color='blue', linewidth=2.5)\n",
    "    plt.plot(plot_df.index, plot_df['Prediksi RandomForest (kWh)'], label='Prediksi RF', color='green', linestyle='--')\n",
    "    plt.plot(plot_df.index, plot_df['Prediksi GradientBoosting (kWh)'], label='Prediksi GB', color='red', linestyle='--')\n",
    "    plt.plot(plot_df.index, plot_df['Prediksi LSTM (kWh)'], label='Prediksi LSTM', color='orange', linestyle='--')\n",
    "    plt.title(f'Grafik Waktu: Prediksi vs Aktual pada Data Test - {plot_suffix}', fontsize=16)\n",
    "    plt.xlabel('Waktu'); plt.ylabel('Konsumsi Energi (kWh)')\n",
    "    plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'time_series_plot_{plot_suffix}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def create_combined_heatmap(performance_data, title_suffix, output_dir):\n",
    "    \"\"\"Membuat dan menyimpan heatmap gabungan dari data kinerja model.\"\"\"\n",
    "    if not performance_data:\n",
    "        print(f\"Tidak ada data kinerja untuk membuat heatmap.\")\n",
    "        return\n",
    "    df = pd.DataFrame(performance_data)\n",
    "    \n",
    "    df['Label Perangkat'] = df['Gedung'] + ' - ' + df['Perangkat']\n",
    "    try:\n",
    "        df.sort_values(by=['Gedung', 'Label Perangkat'], inplace=True)\n",
    "        mae_pivot = df.pivot_table(index='Model', columns='Label Perangkat', values='MAE')\n",
    "        rmse_pivot = df.pivot_table(index='Model', columns='Label Perangkat', values='RMSE')\n",
    "        r2_pivot = df.pivot_table(index='Model', columns='Label Perangkat', values='R2')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat membuat pivot table untuk {title_suffix}: {e}\\nData: {df}\")\n",
    "        return\n",
    "        \n",
    "    num_devices = len(df['Label Perangkat'].unique())\n",
    "    fig_width = max(18, num_devices * 1.5)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(fig_width, 21))\n",
    "    fig.suptitle(f'Heatmap Kinerja Model - {title_suffix}', fontsize=20)\n",
    "    \n",
    "    # Heatmap R2\n",
    "    sns.heatmap(r2_pivot, annot=True, fmt=\".2f\", cmap=\"viridis\", ax=axes[0], linewidths=.5)\n",
    "    axes[0].set_title('R2 Score - Lebih Tinggi Lebih Baik', fontsize=16)\n",
    "    axes[0].set_xlabel(''); axes[0].set_ylabel('Model', fontsize=12)\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Heatmap RMSE\n",
    "    sns.heatmap(rmse_pivot, annot=True, fmt=\".2f\", cmap=\"viridis_r\", ax=axes[1], linewidths=.5)\n",
    "    axes[1].set_title('RMSE (kWh) - Lebih Rendah Lebih Baik', fontsize=16)\n",
    "    axes[1].set_xlabel(''); axes[1].set_ylabel('Model', fontsize=12)\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Heatmap MAE\n",
    "    sns.heatmap(mae_pivot, annot=True, fmt=\".2f\", cmap=\"viridis_r\", ax=axes[2], linewidths=.5)\n",
    "    axes[2].set_title('MAE (kWh) - Lebih Rendah Lebih Baik', fontsize=16)\n",
    "    axes[2].set_xlabel('Gedung - Perangkat / Lokasi', fontsize=12)\n",
    "    axes[2].set_ylabel('Model', fontsize=12)\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    heatmap_path = os.path.join(output_dir, f'heatmap_{title_suffix}.png')\n",
    "    plt.savefig(heatmap_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"\\nHeatmap gabungan disimpan di: {heatmap_path}\")\n",
    "\n",
    "print(\"✅ Fungsi-fungsi pembantu berhasil didefinisikan.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 5. Proses Utama: Melatih Model untuk Setiap File Data\n",
    "# ==============================================================================\n",
    "# Ini adalah inti dari skrip. Sel ini akan melakukan loop melalui semua file\n",
    "# CSV, melakukan seleksi fitur, melatih model, dan menyimpan hasilnya.\n",
    "\n",
    "all_performance_data = []\n",
    "building_predictions_tracker = {}\n",
    "\n",
    "for root, dirs, files in os.walk(SOURCE_DATA_DIR):\n",
    "    if not dirs and not files and root == SOURCE_DATA_DIR:\n",
    "        print(f\"Folder '{SOURCE_DATA_DIR}' kosong. Silakan unggah data Anda.\"); break\n",
    "        \n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(f\"\\n{'='*50}\\nMemproses file: {file_path}\\n{'='*50}\")\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_csv(file_path, index_col='id_time', parse_dates=True)\n",
    "                df.sort_index(inplace=True) # Pastikan data berurutan waktu\n",
    "            except Exception as e:\n",
    "                print(f\"   Gagal membaca file. Error: {e}\"); continue\n",
    "            \n",
    "            existing_cols = [col for col in RELEVANT_COLUMNS if col in df.columns]\n",
    "            df_processed = df.reindex(columns=existing_cols).copy()\n",
    "\n",
    "            if df_processed[TARGET_VARIABLE].isnull().all():\n",
    "                print(\"   - Kolom 'Konsumsi Energi' kosong. Melewati file ini.\")\n",
    "                continue\n",
    "\n",
    "            print(\"   - Membuat fitur historis dari Konsumsi Energi...\")\n",
    "            for lag in range(1, 4):\n",
    "                df_processed[f'Konsumsi_Energi_Lag_{lag}'] = df_processed[TARGET_VARIABLE].shift(lag)\n",
    "            \n",
    "            print(f\"   - Jumlah data sebelum pembersihan NaN: {len(df_processed)}\")\n",
    "            df_processed.dropna(inplace=True)\n",
    "            print(f\"   - Jumlah data setelah pembersihan NaN: {len(df_processed)}\")\n",
    "\n",
    "            print(f\"   - Jumlah data sebelum filter nilai 0: {len(df_processed)}\")\n",
    "            df_final = df_processed[df_processed[TARGET_VARIABLE] > 0].copy()\n",
    "            print(f\"   - Jumlah data setelah filter nilai 0: {len(df_final)}\")\n",
    "\n",
    "            if df_final.empty:\n",
    "                print(\"   - Tidak ada data valid setelah pembersihan total. Melewati file ini.\")\n",
    "                continue\n",
    "            \n",
    "            min_val = df_final[TARGET_VARIABLE].min()\n",
    "            print(f\"   - Verifikasi: Nilai minimum 'Konsumsi Energi' setelah filter adalah {min_val:.4f}\")\n",
    "            if min_val <= 0:\n",
    "                print(\"   - ⚠️ PERINGATAN: Masih ada nilai nol atau negatif setelah filtering!\")\n",
    "\n",
    "            print(\"   - Menghitung matriks korelasi...\")\n",
    "            correlation_matrix = df_final.corr()\n",
    "            \n",
    "            relative_path = os.path.relpath(root, SOURCE_DATA_DIR)\n",
    "            device_output_dir = os.path.join(RESULTS_DIR, relative_path)\n",
    "            os.makedirs(device_output_dir, exist_ok=True)\n",
    "            \n",
    "            plt.figure(figsize=(22, 18)); sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "            plt.title(f'Correlation Matrix - {os.path.basename(root)}', fontsize=16); plt.xticks(rotation=45, ha='right'); plt.yticks(rotation=0)\n",
    "            plt.tight_layout(); plt.savefig(os.path.join(device_output_dir, 'correlation_matrix.png')); plt.close()\n",
    "            print(f\"   - Heatmap korelasi disimpan di: {device_output_dir}\")\n",
    "\n",
    "            correlations = correlation_matrix[TARGET_VARIABLE].abs()\n",
    "            selected_features = correlations[correlations >= 0.4].index.tolist()\n",
    "            \n",
    "            features_for_model = [f for f in selected_features if f != TARGET_VARIABLE]\n",
    "            \n",
    "            print(f\"   - Fitur terpilih dengan korelasi >= 0.4: {features_for_model}\")\n",
    "            if not features_for_model: print(\"   - Tidak ada fitur yang memenuhi ambang korelasi.\"); continue\n",
    "\n",
    "            X = df_final[features_for_model]; y = df_final[TARGET_VARIABLE]\n",
    "            if len(X) < 20: print(f\"   Data tidak cukup untuk pelatihan.\"); continue\n",
    "\n",
    "            # --- PEMBARUAN: Pembagian Data Berurutan (Sequential Split) ---\n",
    "            test_size = 0.15 # 15% data terakhir untuk testing\n",
    "            split_index = int(len(X) * (1 - test_size))\n",
    "            \n",
    "            X_train_val, X_test = X[:split_index], X[split_index:]\n",
    "            y_train_val, y_test = y[:split_index], y[split_index:]\n",
    "            \n",
    "            # Split data training/validasi (bagian ini boleh diacak)\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1, random_state=42, shuffle=False)\n",
    "\n",
    "            if len(X_train) == 0 or len(X_test) == 0: print(f\"   Data tidak cukup setelah di-split.\"); continue\n",
    "\n",
    "            print(f\"   - Ukuran Data: Latih={len(X_train)}, Validasi={len(X_val)}, Uji={len(X_test)} (Berurutan)\")\n",
    "            model_evaluations = train_and_evaluate_models(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "            \n",
    "            device_name = os.path.basename(root)\n",
    "            building_name = relative_path.split(os.sep)[0]\n",
    "            \n",
    "            device_predictions = {name: data['predictions'] for name, data in model_evaluations.items()}\n",
    "            create_prediction_plots(y_test, device_predictions, device_name, device_output_dir)\n",
    "            print(f\"   - Plot prediksi untuk perangkat '{device_name}' disimpan.\")\n",
    "\n",
    "            if building_name not in building_predictions_tracker:\n",
    "                building_predictions_tracker[building_name] = {'y_true': [], 'preds': {'RandomForest': [], 'GradientBoosting': [], 'LSTM': []}}\n",
    "            \n",
    "            building_predictions_tracker[building_name]['y_true'].append(y_test)\n",
    "            for model_name, preds in device_predictions.items():\n",
    "                building_predictions_tracker[building_name]['preds'][model_name].append(preds)\n",
    "            \n",
    "            best_model_name, best_model_rmse, best_model_object = '', float('inf'), None\n",
    "            for model_name, eval_data in model_evaluations.items():\n",
    "                if eval_data['rmse'] < best_model_rmse:\n",
    "                    best_model_rmse, best_model_name, best_model_object = eval_data['rmse'], model_name, eval_data['model']\n",
    "                \n",
    "                path_parts = relative_path.split(os.sep)\n",
    "                if len(path_parts) > 2:\n",
    "                    descriptive_name = f\"{path_parts[1]}_{path_parts[2]}\"\n",
    "                else:\n",
    "                    descriptive_name = path_parts[1]\n",
    "                \n",
    "                all_performance_data.append({\n",
    "                    'Gedung': building_name,\n",
    "                    'Perangkat': descriptive_name,\n",
    "                    'Model': model_name,\n",
    "                    'MAE': eval_data['mae'] / 1000, # Konversi ke kWh\n",
    "                    'RMSE': eval_data['rmse'] / 1000, # Konversi ke kWh\n",
    "                    'R2': eval_data['r2']\n",
    "                })\n",
    "            \n",
    "            if best_model_object:\n",
    "                model_filename = os.path.join(device_output_dir, f'model_terbaik_{best_model_name}.joblib')\n",
    "                if best_model_name != 'LSTM': joblib.dump(best_model_object, model_filename)\n",
    "                else: best_model_object.save(model_filename.replace('.joblib', '.h5'))\n",
    "                print(f\"   ==> Model terbaik ({best_model_name}) disimpan.\")\n",
    "\n",
    "print(\"\\n\\n✅ Proses pelatihan untuk semua file selesai.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# @title 6. Membuat Plot Gabungan dan Heatmap Final\n",
    "# ==============================================================================\n",
    "# Sel terakhir ini akan membuat visualisasi gabungan untuk setiap gedung.\n",
    "\n",
    "print(\"\\nMembuat plot gabungan dan heatmap kinerja...\")\n",
    "for building, data in building_predictions_tracker.items():\n",
    "    print(f\"\\n--- Memproses Gedung: {building.upper()} ---\")\n",
    "    y_true_combined = pd.concat(data['y_true'])\n",
    "    preds_combined = {model: np.concatenate(preds) for model, preds in data['preds'].items()}\n",
    "    \n",
    "    building_output_dir = os.path.join(RESULTS_DIR, building)\n",
    "    os.makedirs(building_output_dir, exist_ok=True)\n",
    "    \n",
    "    create_prediction_plots(y_true_combined, preds_combined, f\"Gabungan_{building.upper()}\", building_output_dir)\n",
    "    print(f\"   - Plot prediksi gabungan untuk gedung '{building}' disimpan di: {building_output_dir}\")\n",
    "\n",
    "if not all_performance_data:\n",
    "    print(\"Tidak ada data kinerja yang dihasilkan. Heatmap tidak dapat dibuat.\")\n",
    "else:\n",
    "    create_combined_heatmap(all_performance_data, \"Gabungan_Semua_Gedung\", RESULTS_DIR)\n",
    "\n",
    "print(\"\\n\\n🏁 Proses Selesai. Semua hasil telah disimpan di folder 'hasil_model'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
